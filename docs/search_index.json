[["index.html", "CDABS R Workshop Series Chapter 1 Introduction 1.1 Acknowledgements 1.2 License", " CDABS R Workshop Series Jean-Paul Courneya and Amy Yarnell 2022-07-07 Chapter 1 Introduction This book was published with bookdown. The bookdown package can be installed from CRAN or Github: install.packages(&quot;bookdown&quot;) # or the development version # devtools::install_github(&quot;rstudio/bookdown&quot;) 1.1 Acknowledgements Chapter 1 Introduction to R and RStudio, and Chapter 2 Welcome to the Tidyverse have been adapted and remixed from The Data Carpentry lesson R for Social Scientists Introduction to R by Monash Bioinformatics Platform. Both of these lessons are licensed under CC BY-4: Creative Commons Attribution 4.0 International License The data in Chapter 2 Welcome to the Tidyverse is from: Van Panhuis W., Cross A., Burke D., Counts of &gt;Measles reported in UNITED STATES OF AMERICA: &gt;1888-2002 (version 2.0, April 1, 2018): Project &gt;Tycho data release, DOI: 10.25337/T7/ptycho.v2.0/US.14189004 Chapter 4 Reproducible Project Management and Chapter 6 Shiny Apps adapts material from: Happy Git with R Chapter 4 Reproducible Reports with R Markdown adapts and remixes material from: R Markdown: the Definitive Guide by Yihui Xie, J.J. Allaire, and Garrett Grolemund. R Markdown Cookbook by Yihui Xie, Christophe Dervieux, and Emily Riederer, licensed under the Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License The Software Carpentry Lesson R for Reproducible Scientific Analysis, in particular the episode Producing Reports with knitr. This lesson is licensed under a CC-BY 4.0 license. Chapter 6 Shiny Apps adapts material from: (STAT 545: Data wrangling, exploration, and analysis with R)[https://stat545.com/shiny-tutorial.html] by Jenny Bryan 1.2 License This work is licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License. You are free to share and adapt this work, so long as you provide proper attribution, share any adaptations or transformations you create of the work with the same license, and do not use for commercial purposes. "],["introduction-to-r-and-rstudio.html", "Chapter 2 Introduction to R and RStudio 2.1 Learning Objectives 2.2 Why learn R? 2.3 Starting out in R 2.4 Using this book 2.5 Working in the Console 2.6 Objects 2.7 Saving code in an R script 2.8 Setting your Working Directory 2.9 Functions and their arguments 2.10 Packages 2.11 Vectors 2.12 Data frames, Tibbles, and Exploring Data 2.13 Exercises", " Chapter 2 Introduction to R and RStudio The next two chapters will provide you with a hands on opportunity to learn R and RStudio. While R is a big topic and we will not be able to cover everything, by the end of this session we hope that you will feel comfortable starting to use R on your own. 2.1 Learning Objectives Understand the value of learning R Navigate RStudio Define terms: object, function, argument, package, vector, data frame. Use help documentation in RStudio. 2.2 Why learn R? R is free, open-source, and cross-platform. Anyone can inspect the source code to see how R works. Because of this transparency, there is less chance for mistakes, and if you (or someone else) find some, you can report and fix bugs. Because R is open source and is supported by a large community of developers and users, there is a very large selection of third-party add-on packages which are freely available to extend R’s native capabilities. R code is great for reproducibility. Reproducibility is when someone else (including your future self) can obtain the same results from the same dataset when using the same analysis. R integrates with other tools to generate manuscripts from your code. If you collect more data, or fix a mistake in your dataset, the figures and the statistical tests in your manuscript are updated automatically. R relies on a series of written commands, not on remembering a succession of pointing and clicking. If you want to redo your analysis because you collected more data, you don’t have to remember which button you clicked in which order to obtain your results; you just have to run your script again. R is interdisciplinary and extensible With 10,000+ packages that can be installed to extend its capabilities, R provides a framework that allows you to combine statistical approaches from many scientific disciplines to best suit the analytical framework you need to analyze your data. For instance, R has packages for image analysis, GIS, time series, population genetics, and a lot more. R works on data of all shapes and sizes. The skills you learn with R scale easily with the size of your dataset. Whether your dataset has hundreds or millions of lines, it won’t make much difference to you. R is designed for data analysis. It comes with special data structures and data types that make handling of missing data and statistical factors convenient. R can connect to spreadsheets, databases, and many other data formats, on your computer or on the web. R produces high-quality graphics. The plotting functionalities in R are endless, and allow you to adjust any aspect of your graph to convey most effectively the message from your data. R has a large and welcoming community. Thousands of people use R daily. Many of them are willing to help you through mailing lists and websites such as Stack Overflow, or on the RStudio community. Questions which are backed up with short, reproducible code snippets are more likely to attract knowledgeable responses. 2.3 Starting out in R R is both a programming language and an interactive environment for data exploration and statistics. Working with R is primarily text-based. The basic mode of use for R is that the user provides commands in the R language and then R computes and displays the result. 2.3.1 Downloading, Installing and Running R Download R can be downloaded from CRAN (The Comprehensive R Archive Network) for Windows, Linux, or Mac. Install Installation of R is like most software packages and you will be guided. Should you have any issues or need help you can refer to R Installation and Administration Running R can be launched from your software or applications launcher or When working at a command line on UNIX or Windows, the command R can be used for starting the main R program in the form R You will see a console similar to this appear: While it is possible to work solely through the console or using a command line interface, the ideal environment to work in R is RStudio. 2.3.2 RStudio RStudio is a user interface for working with R. It is called an Integrated Development Environment (IDE): a piece of software that provides tools to make programming easier. RStudio acts as a sort of wrapper around the R language. You can use R without RStudio, but it’s much more limiting. RStudio makes it easier to import datasets, create and write scripts, and makes using R much more effective. RStudio is also free and open source. To function correctly, RStudio needs R and therefore both need to be installed on your computer. But for this class we’ll be using a browser based version called RStudio Cloud (see directions in the RStudio Cloud section below.) RStudio is divided into four “panes”. The placement of these panes and their content can be customized (see menu, Tools -&gt; Global Options -&gt; Pane Layout). The Default Layout is: Top Left - Source: your scripts and documents Bottom Left - Console: what R would look and be like without RStudio Top Right - Environment/History: look here to see what you have done Bottom Right - Files and more: see the contents of the project/working directory here, like your Script.R file 2.3.3 RStudio Cloud RStudio Cloud is a browser-based version of RStudio. It will allow you to use RStudio without needing to download anything to your computer. You can also easily share your R projects with others. While we recommend downloading RStudio for regular use, we will be using RStudio Cloud for these workshops so we can easily share files and packages with you. Get Started: Create your free RStudio Cloud account at https://rstudio.cloud/plans/free. Go to the class project https://rstudio.cloud/content/4241048 Note the text that marks this as a Temporary Copy. Select the Save a Permanent Copy button to begin working! 2.4 Using this book For these instructions code will appear in the gray box as follows: fake code To run the code you can copy and paste the code and run it in your RStudio session console at the prompt &gt; which looks like a greater than symbol. &gt; fake code The code can also be added to an R Script to be run. When the code is run in RStudio the console prints out results like so: [1] Result In this tutorial results from code will appear like so: ## [1] Result 2.5 Working in the Console The console is an interactive environment for RStudio, click on the “Console” pane, type 3 + 3 and press enter. R displays the result of the calculation. 3 + 3 ## [1] 6 + is called an operator. R has the operators you would expect for for basic mathematics: Arithmetic operators operator meaning + plus - minus * times / divided by ^ exponent Logical Operators operator meaning == exactly equal != not equal to &lt; less than &lt;= less than or equal to &gt; greater than &gt;= greater than or equal to x|y x or y x&amp;y x and y !x not x Spaces can be used to make code easier to read. 2 * 2 == 4 ## [1] TRUE 2.6 Objects 2.6.1 Creating Objects When you have certain values, data, plots, etc that you want to work with You can create objects (make assignments) in R with the assignment operator &lt;-: All R statements where you create objects, assignment statements, have the same form: object_name &lt;- value When reading that code say “object name gets value” in your head. x &lt;- 3 * 4 x ## [1] 12 Once you have an object you can do other calculations with it. x * x ## [1] 144 Objects vs. Variables What are known as objects in R are known as variables in many other programming languages. Depending on the context, object and variable can have drastically different meanings. However, in this lesson, the two words are used synonymously. For more information see: https://cran.r-project.org/doc/manuals/r-release/R-lang.html#Objects 2.6.2 Working with Objects That last example was kind of abstract. So let’s look at a more practical example. Let’s do some calculations with the population of Maryland 1. First we can save the population number to an object. We will call it md_pop because that is short, descriptive, and easy to remember. md_pop &lt;- 6165129 What percentage of the Maryland population is over 18? According to the Census Bureau 2, 78% of the Maryland population is over 18. We can use that to calculate the number of adults in Maryland. md_adult_pop &lt;- .78 * md_pop Next, we want to know what percentage of people in Maryland have been fully vaccinated for COVID-19. As of early July 2022 4.68 million people of all ages have been vaccinated in Maryland 3. So let’s create another object: md_vax_pop &lt;- 4682799 Now we can calculate the percentage of the Maryland population that is vaccinated. percent_vax &lt;- (md_vax_pop / md_pop) * 100 percent_vax ## [1] 75.95622 As more people get vaccinated this can be updated. Let’s say later in year we have 4.9 million Marylanders who are fully vaccinated. We can re-assign the value of md_vax_pop md_vax_pop &lt;- 4900000 Then recalculate percent_vax percent_vax &lt;- (md_vax_pop / md_pop) * 100 percent_vax ## [1] 79.47928 Tip You will make lots of assignments and &lt;- is a pain to type. Avoid the temptation to use =: it will work, but it will cause confusion later. Instead, use RStudio’s keyboard shortcut: Alt + - (the minus sign). Notice that RStudio automagically surrounds &lt;- with spaces, which is a good code formatting practice. Code is miserable to read on a good day, so giveyoureyesabreak and use spaces. 2.6.3 Naming Objects The name for objects must start with a letter, and can only contain letters, numbers, underscores (_)and periods (.). The name of the object should describe what is being assigned so they typically will be multiple words. One convention used is snake_case where lowercase words are separated with _. Another popular style is camelCase where compound words or phrases are written so that each word or abbreviation in the middle of the phrase begins with a capital letter, with no intervening spaces or punctuation and the first letter is lowercase. thisIsCamelCase some_use_snake_case others.use.periods #avoid Others_pRefer.to_RENOUNCEconvention #avoid 2.6.4 Challenge Question Earlier you created an object called md_adult_pop which used Census data to calculate the number of adults living in Maryland. According to the CDC4, 4040544 adults in Maryland have been fully vaccinated against COVID-19. Assign the number of fully vaccinated adults in Maryland to a new object. Use the new object together with md_adult_pop to calculate the percentage of adults in Maryland who are fully vaccinated. Save this to an object called md_adult_percent_vax. 2.7 Saving code in an R script It might seem like you could just as easily calculate the percentage of vaccinated Marylanders by hand. But what if you had to do it again and again, multiple times a day, for days on end? What if you had to make sure multiple people on your team could perform the same task? This is where the real strength of R as a programming language comes in. You can save all the steps of your analysis to a script. This is especially powerful if you have long and complicated analyses. It is how R contributes to reproducible and open science. Open the file vax_count.R. Here we have recorded the steps we just took. So let’s say you were training a new employee to run this very important analysis. Now all they have to do is input the new vaccination number, and run the script. The usual workflow is to save your code in an R script (“.R file”). Go to “File/New File/R Script” to create a new R script. Code in your R script can be sent to the console by selecting it or placing the cursor on the correct line, and then pressing Control-Enter (Command-Enter on a Mac). Tip Add comments to code, using lines starting with the # character. This makes it easier for others to follow what the code is doing (and also for us the next time we come back to it). 2.8 Setting your Working Directory The working directory is the location within which R points to the files system. RStudio sets up a default working directory, typically the home directory of the computer, which can be changed in the global options setting in RStudio. In the code samples provided the data files are located in the R working directory, which can be found with the function getwd. getwd() # get current working directory You can select a different working directory with the function setwd(), and thus avoid entering the full path of the data files. setwd(&quot;&lt;new path&gt;&quot;) # set working directory Note that the forward slash should be used as the path separator even on Windows platform. setwd(&quot;C:/MyDoc&quot;) Alternatively you can go to the working directory and set the working directory using the files panel and clicking the gear wheel for “more” within RStudio. Or by selecting the drop down list found in Tools(Windows) or Session(Mac) in the menu at the top of the RStudio window. 2.9 Functions and their arguments Functions are “canned scripts” that automate more complicated sets of commands including operations assignments, etc. Many functions are predefined, or can be made available by importing R packages (more on that later). A function usually gets one or more inputs called arguments. Functions often (but not always) return a value. A typical example would be the function round(). The input (the argument) must be a number, and the return value (in fact, the output) is that number rounded to the nearest whole number. Executing a function (‘running it’) is called calling the function. You can save the output of a function to an object. The format would look like: b &lt;- round(a) Here, the value of a is given to the round() function, the round() function rounds the number, and returns the value which is then assigned to the object b. The return ‘value’ of a function need not be numerical (like that of sqrt()), and it also does not need to be a single item: it can be a set of things, or even a dataset. We’ll see that when we read data files into R. Arguments can be anything, not only numbers or filenames, but also other objects. Exactly what each argument means differs per function, and must be looked up in the documentation (see below). Some functions take arguments which may either be specified by the user, or, if left out, take on a default value: these are called options. Options are typically used to alter the way the function operates, such as whether it ignores ‘bad values’, or what symbol to use in a plot. However, if you want something specific, you can specify a value of your choice which will be used instead of the default. round() only needs one argument, a number, or object that is storing a numerical value. round(percent_vax) ## [1] 79 Here, we’ve called round() on our percent_vax object and it returned 79. That’s because the default action of the function is to round to the nearest whole number. If we want more digits we can see how to do that by getting information about the round function. We can use args(round) or look at the help for this function using ?round. args(round) ## function (x, digits = 0) ## NULL We see that if we want a different number of digits, we can type digits=2 or however many we want. round(percent_vax, digits = 2) ## [1] 79.48 If you provide the arguments in the exact same order as they are defined you don’t have to name them: round(percent_vax, 2) ## [1] 79.48 And if you do name the arguments, you can switch their order: round(digits = 2, x = percent_vax) ## [1] 79.48 It’s good practice to put the non-optional arguments (like the number you’re rounding) first in your function call, and to specify the names of all optional arguments. If you don’t, someone reading your code might have to look up the definition of a function with unfamiliar arguments to understand what you’re doing. 2.9.1 Getting Help In the previous example we looked up the arguments to round() using args(round) alternatively we couldve looked at the help page for round() to find this out with ?round. To get help about a particular package or function you can access the help pane in RStudio and type its name in the search box. The help() function and ? help operator in R provide access to the documentation pages for R functions, data sets, and other objects, both for packages in the standard R distribution and for contributed packages. To do so type as follows help({function}) help(package = {package name}) ?{function} ?&quot;{package name}&quot; 2.9.2 Challenge: using functions Questions Look at the documentation for the seq function. What does seq do? Give an example of using seq with either the by or length.out argument. 2.10 Packages While you can write your own functions, most functions you use will be part of a package. In R, the fundamental unit of shareable code is the package. A package bundles together code, data, documentation, and tests, and is easy to share with others. As of July 2018, there were over 14,000 packages available on the Comprehensive R Archive Network, or CRAN, the public clearing house for R packages. This huge variety of packages is one of the reasons that R is so successful. Installing a package using RStudio requires selecting the Install Packages Button in the Files, Plots, Packages Pane In the pop up box that results simply type the name of the package and check “install dependencies” and click Install Its also possible for you to install and load packages from the console. Always make sure to put the package name in quotes when installing and setting dependencies = True install.packages(&quot;tidyverse&quot;, dependencies = TRUE) library(tidyverse) You only need to install a package once, but you need to reload it every time you start a new session. 2.11 Vectors 2.11.1 What is a Vector? “Vector” means different things in different fields (mathematics, geometry, biology), but in R it is a fancy name for a collection of values. We call the individual values elements of the vector. It is one of the most common data structures you will work with in R. We can make vectors with the function c( ), for example c(1,2,3). c means “combine”. R is obsessed with vectors, in R even single numbers are vectors of length one. Many things that can be done with a single number can also be done with a vector. For example arithmetic can be done on vectors as it can be on single numbers. 2.11.2 Working with Vectors Let’s say that we have a group of patients in our clinic. (See info in patients_list.txt in your project folder, or download the file.) We can store their names in a vector. patients &lt;- c(&quot;Maria&quot;, &quot;Jon&quot;, &quot;Ali&quot;, &quot;Luis&quot;, &quot;Mei&quot; ) patients ## [1] &quot;Maria&quot; &quot;Jon&quot; &quot;Ali&quot; &quot;Luis&quot; &quot;Mei&quot; If we later wanted to add a name, it’s easy to do so patients &lt;- c(patients, &quot;Emma&quot;) patients ## [1] &quot;Maria&quot; &quot;Jon&quot; &quot;Ali&quot; &quot;Luis&quot; &quot;Mei&quot; &quot;Emma&quot; Maybe we also want to store the weights of these patients. Since these are their weights in pounds, we will call our object weight_lb weight_lb &lt;- c(122, 320, 217, 142, 174, 252) weight_lb ## [1] 122 320 217 142 174 252 So far, we have created vectors of two different data types: character and numeric. You can do arithmetic with numeric vectors. For example, let’s convert the weight of our patients in lbs to the the weight in kilograms by multiplying each weight in lbs by 2.2. We could do this one by one: 122 / 2.2 ## [1] 55.45455 320 / 2.2 ## [1] 145.4545 217 / 2.2 ## [1] 98.63636 etc. But that would be a long and tedious process, especially if you had more than 6 patients. Instead, let’s divide the vector by 2.2 and save that to a new object. We will call this object weight_kg weight_kg &lt;- weight_lb / 2.2 #you could also round the weight weight_kg &lt;- round((weight_lb / 2.2), digits = 2) weight_kg ## [1] 55.45 145.45 98.64 64.55 79.09 114.55 We could use the mean() function to find out the mean weight of patients at our clinic. mean(weight_lb) ## [1] 204.5 You will not be able to perform calculations with character vectors. patients + &quot;Sue&quot; ## Error in patients + &quot;Sue&quot;: non-numeric argument to binary operator Remember we used c() to add a value to our character vector. Data Types There are numerous data types. Some of the other most common data types you will encounter are numeric data, character data and logical data. Vectors of one data type only are called atomic vectors. Read more about vectors and data types in the book R for Data Science Now let’s try working with some logical data. Logical data is the valuesTRUE, FALSE, or NA We want to record if our patients have been fully vaccinated. We will record this as TRUE if they have been, FALSE if they have not been, and NA if we do not have this information. vax_status &lt;- c(TRUE, TRUE, FALSE, NA, TRUE, FALSE) vax_status ## [1] TRUE TRUE FALSE NA TRUE FALSE All vector types have a length property which you can determine with the length() function. length(patients) ## [1] 6 Its helpful to think of the length of a vector as the number of elements in the vector. You can always find out the data type of your vector with the class() function. class(patients) ## [1] &quot;character&quot; class(weight_lb) ## [1] &quot;numeric&quot; class(vax_status) ## [1] &quot;logical&quot; 2.11.3 Missing Data R also has many tools to help with missing data, a very common occurrence. Suppose you tried to calculate the mean of a vector with some missing values (represented here with the logical NA. For example, what if we had failed to capture the weight of some of the patients at our clinic, so our weight vector looks as follows: missing_wgt &lt;- c(122, NA, 217, NA, 174, 252) mean(missing_wgt) ## [1] NA The missing values cause an error, and the mean cannot be correctly calculated. To get around this, you can use the argument na.rm = TRUE. This says to remove the NA values before attempting to perform the calculation. mean(missing_wgt, na.rm = TRUE) ## [1] 191.25 For more on how to work with missing data, check out this Data Carpentry lesson 2.11.4 Mixing Data Types We said above that vectors are supposed to have only one data type, but what happens if we mix multiple data types in one vector? Sometimes the best way to understand R is to try some examples and see what it does. Questions What will happen in each of these examples? Try running this code to see! patient &lt;- c(\"Maria\", 122, TRUE) name_weight &lt;- c(\"John\", 320, 145) weight_status &lt;- c(217, 99, FALSE) Why do you think this happens? Because vectors can only contain one type of data, R chooses a lowest common denominator type of vector, a type that can contain everything we are trying to put in it. A different language might stop with an error, but R tries to soldier on as best it can. A number can be represented as a character string, but a character string can not be represented as a number, so when we try to put both in the same vector R converts everything to a character string. 2.11.5 Indexing and Subsetting vectors Access elements of a vector with [ ], for example patients[1] ## [1] &quot;Maria&quot; patients[4] ## [1] &quot;Luis&quot; You can also assign to a specific element of a vector. We realize that we misspelled the name of our patient John, so we can overwrite our old value by assigning a new name to that element in our vector. patients[2] &lt;- &quot;John&quot; patients ## [1] &quot;Maria&quot; &quot;John&quot; &quot;Ali&quot; &quot;Luis&quot; &quot;Mei&quot; &quot;Emma&quot; Can we use a vector to index another vector? Yes! Lets say we want to know which of our patients have been vaccinated. We know the vaccination status because we have a vector named vax_status lets look at it vax_status ## [1] TRUE TRUE FALSE NA TRUE FALSE Looking at the output we see the index of vaccinated people is elements 1, 2, and 5. or where vax_status is TRUE in the output. We can use this numerical index to subset another from our vector patients which will give us a result that we’ll assign to a new object vax_patients. vaxInd &lt;- c(1,2,5) patients[vaxInd] # this line is saying patients[c(1,2,5)] ## [1] &quot;Maria&quot; &quot;John&quot; &quot;Mei&quot; Now we can assign this vector to an object vax_patients to quickly look at our vaccinated patients. vax_patients &lt;- patients[vaxInd] vax_patients ## [1] &quot;Maria&quot; &quot;John&quot; &quot;Mei&quot; That was great! The problem with this approach is that if we’re in the real world and have a patient population of 1000 it will be really hard to go through our vax_status vector and see who has vax_status is TRUE. Fortunately there is a way to deal with this! Using conditional subsetting We could equivalently have written: patients[vax_status == TRUE] ## [1] &quot;Maria&quot; &quot;John&quot; NA &quot;Mei&quot; This output keeps the NA’s in there and that is not helpful since we only want to know who is vaccinated. Instead we can add a second condition! This condition is awesome because we can now show off our skills of working with missing data! patients[vax_status == TRUE &amp; !is.na(vax_status)] ## [1] &quot;Maria&quot; &quot;John&quot; &quot;Mei&quot; Another thing we can do is to assign our logical expression to an object so we can index our vector using it but also index other data structures like data frames which we are about to learn about. To do this would be like this: # assign logical expression to an object are_vaccinated &lt;- vax_status == TRUE &amp; !is.na(vax_status) # subset the vector according to the logical expression via using the object. patients[are_vaccinated] ## [1] &quot;Maria&quot; &quot;John&quot; &quot;Mei&quot; 2.12 Data frames, Tibbles, and Exploring Data Data frames are another VIP data structure in R. While vectors are one dimensional data structures. Data frames are two dimensional (often called tabular or rectangular data). This is similar to data as you might be used to seeing it in a spreadsheet. You can think of a data frame as consisting of columns of vectors. As vectors,each column in a data frame is of one data type, but the data frame over all can hold multiple data types. A tibble is a particular class of data frame which is common in the tidyverse family of packages. Tibbles are useful for their printing properties and because they are less likely try to change the data type of columns on import (e.g. from character to factor). 2.12.1 Creating data frames Data frames are usually created by reading in a dataset using the read.table() or read.csv() which we will cover in our next session. However, data frames can also be created explicitly with the data.frame() function or they can be coerced from other types of objects like lists. Now that we know vectors form the columns of data frames, we can take the vectors we created for our patient data and combine them together in a data frame. patient_data &lt;- data.frame(patients, weight_lb, weight_kg, vax_status) patient_data ## patients weight_lb weight_kg vax_status ## 1 Maria 122 55.45 TRUE ## 2 John 320 145.45 TRUE ## 3 Ali 217 98.64 FALSE ## 4 Luis 142 64.55 NA ## 5 Mei 174 79.09 TRUE ## 6 Emma 252 114.55 FALSE 2.12.2 Exploring data frames Now we will look at ways to explore the contents of a data frame. For this part of the lesson we will use an object variants, which is a data frame, that has been pre-loaded in your RStudio Cloud project. To access this object locate /cloud/project/data/variants.rds in the file viewer and click on it. In the dialog box that pops up select “OK” In the next session you will learn how to load data in to R but for now we have done this for you so you can focus on learning about exploring data frames. The variants object is a dataset that comes from a real world experiment in E. Coli, you can find out more about the study in the Tenaillon et al 2016 paper 5. The variants object is tabular version of a specialized genomics file type called a VCF file. VCF files are the output of a bioinformatics pipeline that starts with FASTQ files that come from a sequencer and ends with a VCF File. This pipeline typically happens outside of R and RStudio. Your initial instinct with working with this object is to want to see it in a familiar spreadsheet form. The View() function gives us a spreadsheet-like view of the data frame. View(variants) Using the summary() function and, we can learn a lot about the variants data frame including some summary statistics. Let’s examine what this function can tell us: ## get summary statistics on a data frame summary(variants) ## sample_id CHROM POS ID ## Length:801 Length:801 Min. : 1521 Mode:logical ## Class :character Class :character 1st Qu.:1115970 NA&#39;s:801 ## Mode :character Mode :character Median :2290361 ## Mean :2243682 ## 3rd Qu.:3317082 ## Max. :4629225 ## ## REF ALT QUAL FILTER ## Length:801 Length:801 Min. : 4.385 Mode:logical ## Class :character Class :character 1st Qu.:139.000 NA&#39;s:801 ## Mode :character Mode :character Median :195.000 ## Mean :172.276 ## 3rd Qu.:225.000 ## Max. :228.000 ## ## INDEL IDV IMF DP ## Mode :logical Min. : 2.000 Min. :0.5714 Min. : 2.00 ## FALSE:700 1st Qu.: 7.000 1st Qu.:0.8824 1st Qu.: 7.00 ## TRUE :101 Median : 9.000 Median :1.0000 Median :10.00 ## Mean : 9.396 Mean :0.9219 Mean :10.57 ## 3rd Qu.:11.000 3rd Qu.:1.0000 3rd Qu.:13.00 ## Max. :20.000 Max. :1.0000 Max. :79.00 ## NA&#39;s :700 NA&#39;s :700 ## VDB RPB MQB BQB ## Min. :0.0005387 Min. :0.0000 Min. :0.0000 Min. :0.1153 ## 1st Qu.:0.2180410 1st Qu.:0.3776 1st Qu.:0.1070 1st Qu.:0.6963 ## Median :0.4827410 Median :0.8663 Median :0.2872 Median :0.8615 ## Mean :0.4926291 Mean :0.6970 Mean :0.5330 Mean :0.7784 ## 3rd Qu.:0.7598940 3rd Qu.:1.0000 3rd Qu.:1.0000 3rd Qu.:1.0000 ## Max. :0.9997130 Max. :1.0000 Max. :1.0000 Max. :1.0000 ## NA&#39;s :773 NA&#39;s :773 NA&#39;s :773 ## MQSB SGB MQ0F ICB ## Min. :0.01348 Min. :-0.6931 Min. :0.00000 Mode:logical ## 1st Qu.:0.95494 1st Qu.:-0.6762 1st Qu.:0.00000 NA&#39;s:801 ## Median :1.00000 Median :-0.6620 Median :0.00000 ## Mean :0.96428 Mean :-0.6444 Mean :0.01127 ## 3rd Qu.:1.00000 3rd Qu.:-0.6364 3rd Qu.:0.00000 ## Max. :1.01283 Max. :-0.4536 Max. :0.66667 ## NA&#39;s :48 ## HOB AC AN DP4 MQ ## Mode:logical Min. :1 Min. :1 Length:801 Min. :10.00 ## NA&#39;s:801 1st Qu.:1 1st Qu.:1 Class :character 1st Qu.:60.00 ## Median :1 Median :1 Mode :character Median :60.00 ## Mean :1 Mean :1 Mean :58.19 ## 3rd Qu.:1 3rd Qu.:1 3rd Qu.:60.00 ## Max. :1 Max. :1 Max. :60.00 ## ## Indiv gt_PL gt_GT gt_GT_alleles ## Length:801 Min. : 310 Min. :1 Length:801 ## Class :character 1st Qu.: 1760 1st Qu.:1 Class :character ## Mode :character Median : 2290 Median :1 Mode :character ## Mean : 3392 Mean :1 ## 3rd Qu.: 2550 3rd Qu.:1 ## Max. :255156 Max. :1 ## The original dataset had 29 variables, so we get 29 fields that summarize the data for each variable. The QUAL, IMF, and VDB variables (and several others) are numerical data and so you get summary statistics on the min and max values for these columns, as well as mean, median, and interquartile ranges. Many of the other variables (e.g. sample_id) are treated as characters data (more on this in a bit). Running the name variants of the data frame in the console alone shows the first 10 rows, print() with the n argument can be used to show more than the first 10 rows on the console. Keep in mind this allows you to only see the number of variables that fit in the width of your console. So wider console window allows to see more variables. print(variants, n = 25) If its the variable names you’re after you can do that with names() or colnames() colnames(variants) # you could also use names() ## [1] &quot;sample_id&quot; &quot;CHROM&quot; &quot;POS&quot; &quot;ID&quot; ## [5] &quot;REF&quot; &quot;ALT&quot; &quot;QUAL&quot; &quot;FILTER&quot; ## [9] &quot;INDEL&quot; &quot;IDV&quot; &quot;IMF&quot; &quot;DP&quot; ## [13] &quot;VDB&quot; &quot;RPB&quot; &quot;MQB&quot; &quot;BQB&quot; ## [17] &quot;MQSB&quot; &quot;SGB&quot; &quot;MQ0F&quot; &quot;ICB&quot; ## [21] &quot;HOB&quot; &quot;AC&quot; &quot;AN&quot; &quot;DP4&quot; ## [25] &quot;MQ&quot; &quot;Indiv&quot; &quot;gt_PL&quot; &quot;gt_GT&quot; ## [29] &quot;gt_GT_alleles&quot; You have access to details about the number of columns and rows also: # number of rows in variants nrow(variants) ## [1] 801 # number of columns in variants ncol(variants) ## [1] 29 Subsetting data frames Similar to subsetting vectors using bracket syntax [], data frames can be subset using [row,column]. You can provide single dimensions to row and column or variations. variants[4, 5] ## # A tibble: 1 × 1 ## REF ## &lt;chr&gt; ## 1 CTTTTTTT While the output of this subset is a single value the output is considered a data frame. This is typical of tibbles. You can use a column name (in quotes and literally the name of the variable) to subset instead of a number (numerical index): variants[4, &quot;REF&quot;] ## # A tibble: 1 × 1 ## REF ## &lt;chr&gt; ## 1 CTTTTTTT The column or row may be omitted to retrieve the entire row or column. variants[4,] ## # A tibble: 1 × 29 ## sample_id CHROM POS ID REF ALT QUAL FILTER INDEL IDV IMF DP ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;lgl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;lgl&gt; &lt;lgl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 SRR2584863 CP00… 433359 NA CTTT… CTTT… 64 NA TRUE 12 1 12 ## # … with 17 more variables: VDB &lt;dbl&gt;, RPB &lt;dbl&gt;, MQB &lt;dbl&gt;, BQB &lt;dbl&gt;, ## # MQSB &lt;dbl&gt;, SGB &lt;dbl&gt;, MQ0F &lt;dbl&gt;, ICB &lt;lgl&gt;, HOB &lt;lgl&gt;, AC &lt;dbl&gt;, ## # AN &lt;dbl&gt;, DP4 &lt;chr&gt;, MQ &lt;dbl&gt;, Indiv &lt;chr&gt;, gt_PL &lt;dbl&gt;, gt_GT &lt;dbl&gt;, ## # gt_GT_alleles &lt;chr&gt; variants[, &quot;REF&quot;] ## # A tibble: 801 × 1 ## REF ## &lt;chr&gt; ## 1 T ## 2 G ## 3 G ## 4 CTTTTTTT ## 5 CCGC ## 6 C ## 7 C ## 8 G ## 9 ACAGCCAGCCAGCCAGCCAGCCAGCCAGCCAG ## 10 AT ## # … with 791 more rows You can use a vector to retrieve specific rows or columns you may want. This vector can be a named object or created on the spot and passed as an argument in the subsetting. # subset a range of rows using `colon :` variants[35:45, ] ## # A tibble: 11 × 29 ## sample_id CHROM POS ID REF ALT QUAL FILTER INDEL IDV IMF DP ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;lgl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;lgl&gt; &lt;lgl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 SRR25848… CP00… 56613 NA C G 183 NA FALSE NA NA 12 ## 2 SRR25848… CP00… 62118 NA A G 225 NA FALSE NA NA 19 ## 3 SRR25848… CP00… 64042 NA G A 225 NA FALSE NA NA 18 ## 4 SRR25848… CP00… 78808 NA C T 225 NA FALSE NA NA 23 ## 5 SRR25848… CP00… 80113 NA A G 165 NA FALSE NA NA 9 ## 6 SRR25848… CP00… 81158 NA A C 225 NA FALSE NA NA 13 ## 7 SRR25848… CP00… 87462 NA A G 225 NA FALSE NA NA 10 ## 8 SRR25848… CP00… 94370 NA A G 225 NA FALSE NA NA 11 ## 9 SRR25848… CP00… 98286 NA C T 130 NA FALSE NA NA 7 ## 10 SRR25848… CP00… 98404 NA G A 225 NA FALSE NA NA 14 ## 11 SRR25848… CP00… 105581 NA G A 225 NA FALSE NA NA 13 ## # … with 17 more variables: VDB &lt;dbl&gt;, RPB &lt;dbl&gt;, MQB &lt;dbl&gt;, BQB &lt;dbl&gt;, ## # MQSB &lt;dbl&gt;, SGB &lt;dbl&gt;, MQ0F &lt;dbl&gt;, ICB &lt;lgl&gt;, HOB &lt;lgl&gt;, AC &lt;dbl&gt;, ## # AN &lt;dbl&gt;, DP4 &lt;chr&gt;, MQ &lt;dbl&gt;, Indiv &lt;chr&gt;, gt_PL &lt;dbl&gt;, gt_GT &lt;dbl&gt;, ## # gt_GT_alleles &lt;chr&gt; columns_desired &lt;- c(1:3,6:7, 9) variants[, columns_desired] # same as variants[,c(1:3,6:7, 9)] ## # A tibble: 801 × 6 ## sample_id CHROM POS ALT QUAL INDEL ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;lgl&gt; ## 1 SRR2584863 CP000819.1 9972 G 91 FALSE ## 2 SRR2584863 CP000819.1 263235 T 85 FALSE ## 3 SRR2584863 CP000819.1 281923 T 217 FALSE ## 4 SRR2584863 CP000819.1 433359 CTTTTTTTT 64 TRUE ## 5 SRR2584863 CP000819.1 473901 CCGCGC 228 TRUE ## 6 SRR2584863 CP000819.1 648692 T 210 FALSE ## 7 SRR2584863 CP000819.1 1331794 A 178 FALSE ## 8 SRR2584863 CP000819.1 1733343 A 225 FALSE ## 9 SRR2584863 CP000819.1 2103887 ACAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCC… 56 TRUE ## 10 SRR2584863 CP000819.1 2333538 ATT 167 TRUE ## # … with 791 more rows You might be interested in working with a new object that is just your subset from the main data frame. You can do this! # put the first three columns, column 6, column 7 and column 9 of variants into a new data frame called subset_variants subset_variants &lt;- variants[,c(1:3,6:7, 9)] Lets use str() to explore a bit more in depth how data frames work by looking at the “structure” of subset_variants. str(subset_variants) ## tibble [801 × 6] (S3: tbl_df/tbl/data.frame) ## $ sample_id: chr [1:801] &quot;SRR2584863&quot; &quot;SRR2584863&quot; &quot;SRR2584863&quot; &quot;SRR2584863&quot; ... ## $ CHROM : chr [1:801] &quot;CP000819.1&quot; &quot;CP000819.1&quot; &quot;CP000819.1&quot; &quot;CP000819.1&quot; ... ## $ POS : num [1:801] 9972 263235 281923 433359 473901 ... ## $ ALT : chr [1:801] &quot;G&quot; &quot;T&quot; &quot;T&quot; &quot;CTTTTTTTT&quot; ... ## $ QUAL : num [1:801] 91 85 217 64 228 210 178 225 56 167 ... ## $ INDEL : logi [1:801] FALSE FALSE FALSE TRUE TRUE FALSE ... Ok, thats a lot to unpack! Some things to notice. In the output of str() we see the object type tibble (S3: tbl_df/tbl/data.frame) is displayed in the first row along with its dimensions [801 × 6], in this case 801 observations (rows) and 6 variables (columns). Each variable (column) has a name (e.g. sample_id). This is followed by the object mode (e.g. chr, num, etc.). Notice that before each variable name there is a $ - lets look at this a little more since this is another way we can subset. So far we have used numbers to retrieve columns from our data frames however you might prefer using the column name. To use a name we can use $ to retrieve columns. Occasionally it is also useful to use [[ ]] to retrieve columns, for example if the column name we want is stored in a variable. # extract the &quot;ALT&quot; column to a new object alt_alleles &lt;- subset_variants$ALT Lets look at the first few rows of alt_alleles using head() head(alt_alleles) ## [1] &quot;G&quot; &quot;T&quot; &quot;T&quot; &quot;CTTTTTTTT&quot; &quot;CCGCGC&quot; &quot;T&quot; This could have also been written using the double bracket notation double_bracket_ALT &lt;- subset_variants[[&quot;ALT&quot;]] # look at the first fiew rows of it head(double_bracket_ALT) ## [1] &quot;G&quot; &quot;T&quot; &quot;T&quot; &quot;CTTTTTTTT&quot; &quot;CCGCGC&quot; &quot;T&quot; To get the ALT value for row 4 we could use a mix of $ and bracket [] subsetting. subset_variants$ALT[4] ## [1] &quot;CTTTTTTTT&quot; (you may notice at this point were using bracket notation on a vector because the output of a $ subsetting is a vector, data frames are made up of columns of vectors!!!) Logical Subsetting(Indexing) We have already used logical indexing for subsetting a vector. Lets briefly look at an example of doing this with a data frame. Imagine that you want to have a data frame subset_variants_low_qual that is records from subset_variants that have very low quality scores. low_qual_idX &lt;- subset_variants$QUAL &lt; 139 # take a peak at the head of this head(low_qual_idX) ## [1] TRUE TRUE FALSE TRUE FALSE FALSE # how many are TRUE? sum(low_qual_idX) ## [1] 200 sum treats TRUE as 1 and FALSE as 0, so it tells us the number of TRUE elements in the vector (low_qual_idx). We can use this logical vector to get the subset data frame subset_variants_low_qual that is only variants below the threshold we set. subset_variants_low_qual &lt;- subset_variants[low_qual_idX, ] # take a look at the subset confirming with the first few values that they are below the threshold head(subset_variants_low_qual) ## # A tibble: 6 × 6 ## sample_id CHROM POS ALT QUAL INDEL ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;lgl&gt; ## 1 SRR2584863 CP000819.1 9972 G 91 FALSE ## 2 SRR2584863 CP000819.1 263235 T 85 FALSE ## 3 SRR2584863 CP000819.1 433359 CTTTTTTTT 64 TRUE ## 4 SRR2584863 CP000819.1 2103887 ACAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCA… 56 TRUE ## 5 SRR2584863 CP000819.1 2407766 C 104 FALSE ## 6 SRR2584863 CP000819.1 2618472 T 31.9 FALSE Introducing Factors Factors are the final major data type we will introduce in this R lessons. Factors can be thought of as vectors which are specialized for categorical data. Given R’s specialization for statistics, this make sense since categorical and continuous variables are usually treated differently. Sometimes you may want to have data treated as a factor, but in other cases, this may be undesirable. To learn about factors we will work with the column subset_variants$ALT. First its important to know what type of object we’re working with using typeof() and then look at the first 15 elements of it using head(): typeof(subset_variants$ALT) ## [1] &quot;character&quot; head(subset_variants$ALT, n = 15) ## [1] &quot;G&quot; ## [2] &quot;T&quot; ## [3] &quot;T&quot; ## [4] &quot;CTTTTTTTT&quot; ## [5] &quot;CCGCGC&quot; ## [6] &quot;T&quot; ## [7] &quot;A&quot; ## [8] &quot;A&quot; ## [9] &quot;ACAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAG&quot; ## [10] &quot;ATT&quot; ## [11] &quot;C&quot; ## [12] &quot;C&quot; ## [13] &quot;T&quot; ## [14] &quot;T&quot; ## [15] &quot;A&quot; There are 801 alleles (one for each row). To simplify, lets look at just the single-nuleotide alleles (SNPs). Before doing so we can confirm that SNPs are the most abundant using table(), we will also sort the output decreasing sort(table(subset_variants$ALT), decreasing = TRUE) ## ## A ## 211 ## T ## 203 ## G ## 154 ## C ## 139 ## GCCCCCC ## 6 ## GCCCCCCC ## 6 ## CAAAAAAA ## 4 ## TCCCCCCC ## 4 ## CAAAAAAAA ## 3 ## TGGGGGGG ## 3 ## TGGGGGGGG ## 3 ## AC ## 2 ## ACCCCC ## 2 ## ACCCCCCCC ## 2 ## AGGGGG ## 2 ## AGGGGGG ## 2 ## AGGGGGGG ## 2 ## ATT ## 2 ## ATTTTTTT ## 2 ## CCGCGC ## 2 ## CGGGGGGG ## 2 ## CTTTTTT ## 2 ## CTTTTTTTT ## 2 ## GA ## 2 ## GAAAAAAA ## 2 ## GCCCCCCCC ## 2 ## GTTT ## 2 ## GTTTTTTTT ## 2 ## TCCCCCC ## 2 ## TCCCCCCCCC ## 2 ## ACAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAG ## 1 ## ACAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAG ## 1 ## AGCGCGCGCG ## 1 ## AGG ## 1 ## AGGGGGGGG ## 1 ## AGGGGGGGGG ## 1 ## AT ## 1 ## ATTTTTTTT ## 1 ## CA ## 1 ## CAAAAA ## 1 ## CAAAAAAAAAA ## 1 ## CATGATGATGAT ## 1 ## CGGGGGG ## 1 ## CTTTTTTTTT ## 1 ## GCCCCC ## 1 ## GTTCTTCTTC ## 1 ## GTTTCGCT ## 1 ## GTTTTTT ## 1 ## GTTTTTTT ## 1 ## GTTTTTTTTT ## 1 ## GTTTTTTTTTT ## 1 ## TAAA ## 1 ## TAAAAA ## 1 ## TAAAAAAAA ## 1 ## TCCCCCCCCCC ## 1 ## TGGGGGG ## 1 ## TGGGGGGGGG ## 1 We can create a object snps_variants using a new type of subsetting with %in% that keeps rows corresponding to a vector of values in our case the values “A”, “C”, “G”, “T”. snps_variants &lt;- subset_variants[subset_variants$ALT %in% c(&quot;A&quot;, &quot;C&quot;, &quot;G&quot;, &quot;T&quot;) ,] When we look at str() did this make our object a factor? str(snps_variants$ALT) ## chr [1:707] &quot;G&quot; &quot;T&quot; &quot;T&quot; &quot;T&quot; &quot;A&quot; &quot;A&quot; &quot;C&quot; &quot;C&quot; &quot;T&quot; &quot;T&quot; &quot;A&quot; &quot;C&quot; &quot;A&quot; &quot;G&quot; &quot;C&quot; ... NO! The output says snps_variants$ALT is a chr and we promised you factors! To turn this or any other character vector that should be a categorical variable into a factor we can use the function factor() lets do this and look at its structure again. snps_variants$ALT &lt;- factor(snps_variants$ALT) str(snps_variants$ALT) ## Factor w/ 4 levels &quot;A&quot;,&quot;C&quot;,&quot;G&quot;,&quot;T&quot;: 3 4 4 4 1 1 2 2 4 4 ... What we get back are the categories (“A”,”C”,”G”,”T”) in our factor; these are called “Levels”. Levels are the different categories contained in a factor. For the sake of efficiency, R stores the content of a factor as a vector of integers, which an integer is assigned to each of the possible levels (a hold over from the old days when treating things as numbers saved space and processing time on the computer) By default, R will organize the levels in a factor in alphabetical order. So the first level in this factor is “A” and the final is “T”. We hope you have enjoyed this crash course in Factors! Now we will learn how to quickly explore our data with plots 2.12.3 Quickly exploring data with plots For very quick exploration of data, it’s sometimes useful to use the plotting functions in base R. These are installed by default with R and do not require any additional packages to be installed. They’re quick to type, straightforward to use in simple cases, and run very quickly. If you want to do anything beyond very simple plots, though, it’s generally better to switch to ggplot2 which you will learn in Session 3 of the CDABS summeR workshops. We will pick up with factors with our first example. One of the most common uses for factors will be when you plot categorical values. For example, suppose we want to know how many of our snp_variants had each possible SNP we could generate a plot: plot(snps_variants$ALT) This isn’t a particularly pretty example of a plot but it works! If you recall, factors are ordered alphabetically. That might make sense, but categories (e.g., “red”, “blue”, “green”) often do not have an intrinsic order. What if we wanted to order our plot according to the numerical value (i.e., in order of SNP frequency)? We can enforce an order on our factors and plot again!: snps_variants$ordered_factor_snps &lt;- factor(snps_variants$ALT, levels = names(sort(table(snps_variants$ALT)))) Let’s deconstruct this from the inside out (you can try each of these commands to see why this works): We create a table of factor_snps to get the frequency of each SNP: table(snps_variants$ALT) We sort this table: sort(table(snps_variants$ALT)); use the decreasing = parameter for this function if you wanted to change from the default of FALSE Using the names function gives us just the character names of the table sorted by frequencies:names(sort(table(snps_variants$ALT))) The factor() function is what allows us to create a factor. We give it the snps_variants$ALT object as input, and use the levels= parameter to enforce the ordering of the levels. Taking a look at the plot we see it is reordered and very easy on the eyes!: plot(snps_variants$ordered_factor_snps) Wow! Adenine is the most frequent SNP in this data 2.13 Exercises Open a new R script. Save it to your project folder. Use this script to record the answers to the exercises Use a comment to indicate the exercise number you are answering. Create an object with the value of your name. Create an object with the value of your age. Determine the data type of each of the two objects you created above with the class() function. Use one of the strategies you learned in Getting Help to look up what the rm() function does. How would you use this on the objects you created in Questions 3 and 4? Create a vector of the following names: Marcia, Jan, Cindy. Assign this to an object called brady_girls. Create another vector of the following names: Greg, Peter, Bobby. Assign this to an object called brady_boys. Combine the brady_girls and brady_boys vectors together and assign to an object called brady_bunch. How would you subset the 4th element in the brady_bunch vector? Use the library() function to load the package called datasets. This package contains a number of example datasets you can use for practice. Use head() to look at the beginning of the dataset called ToothGrowth. How would you find the number of columns and rows in ToothGrowth? How would you find summary information about this dataset? Use bracket notation to select the item in the 5th row and 2nd column of ToothGrowth. Use bracket notation to select the 5th through 10th rows of ToothGrowth. Use dollar sign notation to look at the len column of ToothGrowth. Find the mean of the len column. Use logical subsetting to save all the rows where the value in the supp column is OJ. Assign this to a new object. Population data from https://www.census.gov/quickfacts/MD↩︎ Population data from https://www.census.gov/quickfacts/MD↩︎ Vaccination information from https://coronavirus.maryland.gov/#Vaccine↩︎ Centers for Disease Control and Prevention. COVID Data Tracker. Atlanta, GA: US Department of Health and Human Services, CDC; 2022, July 06. https://covid.cdc.gov/covid-data-tracker↩︎ Tenaillon O, Barrick JE, Ribeck N, Deatherage DE, Blanchard JL, Dasgupta A, Wu GC, Wielgoss S, Cruveiller S, Médigue C, Schneider D, Lenski RE. Tempo and mode of genome evolution in a 50,000-generation experiment (2016) Nature. 536(7615): 165–170. Paper, Supplemental materials Data on NCBI SRA: https://trace.ncbi.nlm.nih.gov/Traces/sra/?study=SRP064605 Data on EMBL-EBI ENA: https://www.ebi.ac.uk/ena/data/view/PRJNA295606↩︎ "],["welcome-to-the-tidyverse.html", "Chapter 3 Welcome to the Tidyverse 3.1 Install 3.2 The Data 3.3 Importing data 3.4 Working with columns 3.5 Working with rows 3.6 Joining Datasets", " Chapter 3 Welcome to the Tidyverse In this lesson we will be using a group of packages which are part of what is known as the tidyverse. These packages include : readr for importing data into R dplyr for handling common data wrangling tasks for tabular data tidyr which enables you to swiftly convert between different data formats (long vs. wide) for plotting and analysis lubridate for working with dates ggplot2 for visualizing data. For the full list of tidyverse packages and documentation visit tidyverse.org You can install these packages individually, or you can install the entire tidyverse in one go. 3.1 Install First we are going to use install.packages() to install tidyverse. Then we are going to load tidyverse with the library() function. You only need to install a package once, but you will load it each time you start a new r session. To learn more about dplyr and tidyr after the workshop, you may want to check out this handy data transformation with dplyr cheatsheet and this one about tidyr. #install tidyverse if you haven&#39;t yet #install.packages(&quot;tidyverse&quot;) #load tidyverse library(tidyverse) ## ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ── ## ✔ ggplot2 3.3.6 ✔ purrr 0.3.4 ## ✔ tibble 3.1.7 ✔ dplyr 1.0.9 ## ✔ tidyr 1.2.0 ✔ stringr 1.4.0 ## ✔ readr 2.1.2 ✔ forcats 0.5.1 ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ── ## ✖ dplyr::filter() masks stats::filter() ## ✖ dplyr::lag() masks stats::lag() 3.2 The Data For this lesson we will be using data which comes from Project Tycho - an open data project from the University of Pittsburgh which provides standardized datasets on numerous diseases to aid global health research. Throughout this lesson, we will be using a dataset from Project Tycho featuring historical counts of measles cases in the U.S.. We want to clean and present this data in a way that makes it easy to see how measles cases fluctuated over time. Our end result will be this graph: A useful feature of Project Tycho data is their use of a common set of variables. Read more about their data format. 3.3 Importing data Now let’s import the data we’ll be working with. You can import data with code, or you can use RStudio’s GUI. Let’s look at both. In the environment pane, select the button that says Import Dataset and choose the option From text (readr). This means we are going to be using the reader package, which is part of the tidyverse to read a file. Select Browse in the dialog box that opens, and navigate to your data folder and choose the file called measles_us.csv A new window will open with a spreadsheet view of the data. We can use this window to make some choices about how the data is imported. RStudio will use the file name as the default name for your dataset, but you could change it to whatever you want. In this case measles_us works pretty well. RStudio will also try to guess the data type of your columns. It will mostly get it right, but it is not unusual that you will manually need to tell it what data type certain columns are. For example, let’s look at the columns PeriodStartDate and PeriodEndDate. These columns contain dates, but RStudio wants to read them as character data. This is very common when importing data. Let’s change these columns to the date data type, by using the drop down menu to select date data. You will be asked to confirm that the input format of the date is %m/%d/%Y which is like writing mm/dd/YYYY. The program needs to know what the correct input date is so it can return the right output date YYYY-mm-dd, the international standard date format. Now our data is ready to import. Your import screen should look like: We can select the import button. But as you may have noticed, the code behind this import dialog box is also being generated. Use the clipboard icon to copy the code. Let’s paste that into our script.R file. So what does all this code actually mean? We are using a function from the readr package called read_csv(). This function takes as an argument the path to where the file is located. This can take the form of an absolute path, a relative path to the working directory, or a url. The col_types argument lets you specify the data type by column name, and the na argument lets you specify the value that should be read as NA in your data set. Remember to make sure you set your working directory before trying to import data! library(readr) measles_us &lt;- read_csv( &quot;data/measles_us.csv&quot;, col_types = cols( PeriodStartDate = col_date(format = &quot;%m/%d/%Y&quot;), PeriodEndDate = col_date(format = &quot;%m/%d/%Y&quot;)), na = &quot;NA&quot; ) View(measles_us) After reading the data, you will typically want to inspect it and make sure everything looks okay. There are several ways of doing this. In your script above, View() opens the data as a file in your documents pane. The most basic way is to call the name of the object as we did in the last lesson with vectors. Since we used read_csv(), the object will print as a tibble. The problem with this, is that it will only show as many columns as can fit in your window. So it’s good to know a few other ways to look at your data. measles_us ## # A tibble: 422,051 × 9 ## ConditionName CountryName Admin1Name Admin1ISO PeriodStartDate PeriodEndDate ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;date&gt; &lt;date&gt; ## 1 Measles UNITED STAT… WISCONSIN US-WI 1927-11-20 1927-11-26 ## 2 Measles UNITED STAT… WISCONSIN US-WI 1927-11-27 1927-12-03 ## 3 Measles UNITED STAT… WISCONSIN US-WI 1927-12-04 1927-12-10 ## 4 Measles UNITED STAT… WISCONSIN US-WI 1927-12-18 1927-12-24 ## 5 Measles UNITED STAT… WISCONSIN US-WI 1927-12-25 1927-12-31 ## 6 Measles UNITED STAT… WISCONSIN US-WI 1928-01-01 1928-01-07 ## 7 Measles UNITED STAT… WISCONSIN US-WI 1928-01-08 1928-01-14 ## 8 Measles UNITED STAT… WISCONSIN US-WI 1928-01-15 1928-01-21 ## 9 Measles UNITED STAT… WISCONSIN US-WI 1928-01-22 1928-01-28 ## 10 Measles UNITED STAT… WISCONSIN US-WI 1928-01-29 1928-02-04 ## # … with 422,041 more rows, and 3 more variables: ## # PartOfCumulativeCountSeries &lt;dbl&gt;, SourceName &lt;chr&gt;, CountValue &lt;dbl&gt; The glimpse() function lets you see the column names and data types clearly. This function is part of the tibble package which is loaded with the core tidyverse. #summary of columns and first few entries glimpse(measles_us) ## Rows: 422,051 ## Columns: 9 ## $ ConditionName &lt;chr&gt; &quot;Measles&quot;, &quot;Measles&quot;, &quot;Measles&quot;, &quot;Measles&quot;… ## $ CountryName &lt;chr&gt; &quot;UNITED STATES OF AMERICA&quot;, &quot;UNITED STATES… ## $ Admin1Name &lt;chr&gt; &quot;WISCONSIN&quot;, &quot;WISCONSIN&quot;, &quot;WISCONSIN&quot;, &quot;WI… ## $ Admin1ISO &lt;chr&gt; &quot;US-WI&quot;, &quot;US-WI&quot;, &quot;US-WI&quot;, &quot;US-WI&quot;, &quot;US-WI… ## $ PeriodStartDate &lt;date&gt; 1927-11-20, 1927-11-27, 1927-12-04, 1927-… ## $ PeriodEndDate &lt;date&gt; 1927-11-26, 1927-12-03, 1927-12-10, 1927-… ## $ PartOfCumulativeCountSeries &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, … ## $ SourceName &lt;chr&gt; &quot;US Nationally Notifiable Disease Surveill… ## $ CountValue &lt;dbl&gt; 85, 120, 84, 106, 39, 45, 28, 140, 48, 85,… You can also use the head() function to view the first n rows. The function defaults to 6 rows, but you can specify the number you want with an argument. Below we ask to see just the first 5 rows. #first n rows (defaults to 6) head(measles_us, n = 5) ## # A tibble: 5 × 9 ## ConditionName CountryName Admin1Name Admin1ISO PeriodStartDate PeriodEndDate ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;date&gt; &lt;date&gt; ## 1 Measles UNITED STATE… WISCONSIN US-WI 1927-11-20 1927-11-26 ## 2 Measles UNITED STATE… WISCONSIN US-WI 1927-11-27 1927-12-03 ## 3 Measles UNITED STATE… WISCONSIN US-WI 1927-12-04 1927-12-10 ## 4 Measles UNITED STATE… WISCONSIN US-WI 1927-12-18 1927-12-24 ## 5 Measles UNITED STATE… WISCONSIN US-WI 1927-12-25 1927-12-31 ## # … with 3 more variables: PartOfCumulativeCountSeries &lt;dbl&gt;, SourceName &lt;chr&gt;, ## # CountValue &lt;dbl&gt; 3.4 Working with columns 3.4.1 Select() To select columns of a data frame, use select(). This is a great way to create a smaller data frame with only the variables you are interested in. select() is a function. Remember that functions have arguments which go inside the parentheses. The first argument to this function is the name of the data object, which in this case is measles_us, and the subsequent arguments are the names of the columns we want to keep, separated by commas. Let’s try selecting the Admin1Name column and the CountValue column. select(measles_us, Admin1Name, CountValue) ## # A tibble: 422,051 × 2 ## Admin1Name CountValue ## &lt;chr&gt; &lt;dbl&gt; ## 1 WISCONSIN 85 ## 2 WISCONSIN 120 ## 3 WISCONSIN 84 ## 4 WISCONSIN 106 ## 5 WISCONSIN 39 ## 6 WISCONSIN 45 ## 7 WISCONSIN 28 ## 8 WISCONSIN 140 ## 9 WISCONSIN 48 ## 10 WISCONSIN 85 ## # … with 422,041 more rows As you can imagine, if you had a number of columns to select, it could get tiresome to write them all out. One way around this is to use a colon : to name a range of adjacent columns. select(measles_us, ConditionName:Admin1ISO) ## # A tibble: 422,051 × 4 ## ConditionName CountryName Admin1Name Admin1ISO ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Measles UNITED STATES OF AMERICA WISCONSIN US-WI ## 2 Measles UNITED STATES OF AMERICA WISCONSIN US-WI ## 3 Measles UNITED STATES OF AMERICA WISCONSIN US-WI ## 4 Measles UNITED STATES OF AMERICA WISCONSIN US-WI ## 5 Measles UNITED STATES OF AMERICA WISCONSIN US-WI ## 6 Measles UNITED STATES OF AMERICA WISCONSIN US-WI ## 7 Measles UNITED STATES OF AMERICA WISCONSIN US-WI ## 8 Measles UNITED STATES OF AMERICA WISCONSIN US-WI ## 9 Measles UNITED STATES OF AMERICA WISCONSIN US-WI ## 10 Measles UNITED STATES OF AMERICA WISCONSIN US-WI ## # … with 422,041 more rows Another helpful tool that the tidyverse provides is the pipe operator which looks like %&gt;%. The pipe is made available via the magrittr package, installed automatically with dplyr. If you use RStudio, you can type the pipe with Ctrl + Shift + M if you have a PC or Cmd + Shift + M if you have a Mac. With the pipe you start with your data object and pipe it to the function, rather than naming the data as your first argument. So, the pipe becomes especially valuable when you have a number of steps that you want to connect. Another benefit of using the pipe in RStudio is that the interface will supply column names to you in the auto complete. This helps so you do not need to remember sometimes lengthy column names, and you are less likely to get an error from a typo. measles_us %&gt;% select(Admin1Name, PartOfCumulativeCountSeries) ## # A tibble: 422,051 × 2 ## Admin1Name PartOfCumulativeCountSeries ## &lt;chr&gt; &lt;dbl&gt; ## 1 WISCONSIN 0 ## 2 WISCONSIN 0 ## 3 WISCONSIN 0 ## 4 WISCONSIN 0 ## 5 WISCONSIN 0 ## 6 WISCONSIN 0 ## 7 WISCONSIN 0 ## 8 WISCONSIN 0 ## 9 WISCONSIN 0 ## 10 WISCONSIN 0 ## # … with 422,041 more rows Now unfortunately, we did not save this to an object, so while it prints out to the console, we cannot really do anything with these results. So now, let’s think through which columns we want for our analysis and save this to a new object called measles_us_mod. So if we look at our data, we see that the columns ConditionName, CountryName, and SourceName have the same values throughout the data set. So it seems redundant to keep those. Admin1ISO has redundant information to Admin1Name, so we can probably get rid of that as well. For this particular analysis we are going to take a state level view of measles, so we do not need Admin2Name and CityName either. That leaves us with Admin1Name, PeriodStartDate, PeriodEndDate, PartOfCumulativeCountSeries, and CountValue. measles_us_mod &lt;- measles_us %&gt;% select( Admin1Name, PeriodStartDate, PeriodEndDate, PartOfCumulativeCountSeries, CountValue ) #inspect our new data frame glimpse(measles_us_mod) ## Rows: 422,051 ## Columns: 5 ## $ Admin1Name &lt;chr&gt; &quot;WISCONSIN&quot;, &quot;WISCONSIN&quot;, &quot;WISCONSIN&quot;, &quot;WI… ## $ PeriodStartDate &lt;date&gt; 1927-11-20, 1927-11-27, 1927-12-04, 1927-… ## $ PeriodEndDate &lt;date&gt; 1927-11-26, 1927-12-03, 1927-12-10, 1927-… ## $ PartOfCumulativeCountSeries &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, … ## $ CountValue &lt;dbl&gt; 85, 120, 84, 106, 39, 45, 28, 140, 48, 85,… Now when you look in your environment pane, you should see your new object which as the same number of rows but 6 instead of 11 columns (or variables) 3.4.2 Renaming columns Sometimes when you receive data, you may find that the column names are not very descriptive or useful, and it may be necessary to rename them. You can assign new names to columns when you select them select(newColumnName = OldColumnName) or you can use the rename() function. Like naming objects, you should use a simple, descriptive, relatively short name without spaces for your column names. measles_us_mod &lt;- rename(measles_us_mod, State = Admin1Name) 3.4.3 Creating new columns with mutate() Frequently you’ll want to create new columns based on the values in existing columns, for example to do unit conversions, or to find the ratio of values in two columns. For this you can use the mutate() function. The transmute() function is similar, but replaces old columns with the new one. We know that each row in our dataset represents some time span, but we’re not sure what that span is. Below we use mutate() to create a new column called Span, which gives the number of days between the PeriodEndDate column and the PeriodStartDate column. This is why it is important to make sure your date columns are parsed properly as dates when importing your data. If the dates had been left as character data, it would not have been possible to do arithmetic with them. measles_us_mod &lt;- mutate(measles_us_mod, Span = PeriodEndDate - PeriodStartDate) measles_us_mod ## # A tibble: 422,051 × 6 ## State PeriodStartDate PeriodEndDate PartOfCumulativeCou… CountValue Span ## &lt;chr&gt; &lt;date&gt; &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;drt&gt; ## 1 WISCONSIN 1927-11-20 1927-11-26 0 85 6 da… ## 2 WISCONSIN 1927-11-27 1927-12-03 0 120 6 da… ## 3 WISCONSIN 1927-12-04 1927-12-10 0 84 6 da… ## 4 WISCONSIN 1927-12-18 1927-12-24 0 106 6 da… ## 5 WISCONSIN 1927-12-25 1927-12-31 0 39 6 da… ## 6 WISCONSIN 1928-01-01 1928-01-07 0 45 6 da… ## 7 WISCONSIN 1928-01-08 1928-01-14 0 28 6 da… ## 8 WISCONSIN 1928-01-15 1928-01-21 0 140 6 da… ## 9 WISCONSIN 1928-01-22 1928-01-28 0 48 6 da… ## 10 WISCONSIN 1928-01-29 1928-02-04 0 85 6 da… ## # … with 422,041 more rows It’s hard to get a sense of what different time spans are present in our data. We can use the count() function to help us figure that out. count(measles_us_mod,Span) ## # A tibble: 59 × 2 ## Span n ## &lt;drtn&gt; &lt;int&gt; ## 1 6 days 338063 ## 2 13 days 558 ## 3 20 days 693 ## 4 27 days 782 ## 5 34 days 857 ## 6 41 days 929 ## 7 48 days 913 ## 8 55 days 997 ## 9 62 days 1083 ## 10 69 days 1136 ## # … with 49 more rows All those different time spans will get us into trouble when we try to work with the data. So next we need to filter the dataset for only the rows we want. 3.5 Working with rows 3.5.1 filter() select() lets us choose columns. To choose rows based on a specific criteria, we can use the filter() function. The arguments after the data frame are the condition(s) we want for our final dataframe to adhere to. Specify conditions using logical operator: operator meaning == exactly equal != not equal to &lt; less than &lt;= less than or equal to &gt; greater than &gt;= greater than or equal to x|y x or y x&amp;y x and y !x not x We’ll come back to our problem of different time spans in a moment. First, let’s try filtering our data by just one condition. We want to see just the rows that contain counts from Maryland. measles_us_mod %&gt;% filter(State == &quot;MARYLAND&quot;) ## # A tibble: 7,246 × 6 ## State PeriodStartDate PeriodEndDate PartOfCumulativeCoun… CountValue Span ## &lt;chr&gt; &lt;date&gt; &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;drt&gt; ## 1 MARYLAND 1927-11-27 1927-12-03 0 64 6 da… ## 2 MARYLAND 1927-12-04 1927-12-10 0 88 6 da… ## 3 MARYLAND 1927-12-18 1927-12-24 0 105 6 da… ## 4 MARYLAND 1927-12-25 1927-12-31 0 109 6 da… ## 5 MARYLAND 1928-01-01 1928-01-07 0 175 6 da… ## 6 MARYLAND 1928-01-08 1928-01-14 0 249 6 da… ## 7 MARYLAND 1928-01-15 1928-01-21 0 345 6 da… ## 8 MARYLAND 1928-01-22 1928-01-28 0 365 6 da… ## 9 MARYLAND 1928-01-29 1928-02-04 0 504 6 da… ## 10 MARYLAND 1928-02-05 1928-02-11 0 563 6 da… ## # … with 7,236 more rows When matching strings you must be exact. R is case-sensitive. So State == \"Maryland\" or State == \"maryland\" would return 0 rows. You can add additional conditions to filter by, separated by commas or other logical operators like &amp;, &gt;, and &gt;. Below we want just the rows for Maryland, and only include periods where the count was more than 500 reported cases. Note that while you need quotation marks around character data, you do not need them around numeric data. measles_us_mod %&gt;% filter(State == &quot;MARYLAND&quot; &amp; CountValue &gt; 500) ## # A tibble: 328 × 6 ## State PeriodStartDate PeriodEndDate PartOfCumulativeCoun… CountValue Span ## &lt;chr&gt; &lt;date&gt; &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;drt&gt; ## 1 MARYLAND 1928-01-29 1928-02-04 0 504 6 da… ## 2 MARYLAND 1928-02-05 1928-02-11 0 563 6 da… ## 3 MARYLAND 1928-02-12 1928-02-18 0 696 6 da… ## 4 MARYLAND 1928-02-19 1928-02-25 0 750 6 da… ## 5 MARYLAND 1928-02-26 1928-03-03 0 1012 6 da… ## 6 MARYLAND 1928-03-04 1928-03-10 0 951 6 da… ## 7 MARYLAND 1928-03-11 1928-03-17 0 1189 6 da… ## 8 MARYLAND 1928-03-18 1928-03-24 0 1163 6 da… ## 9 MARYLAND 1928-03-25 1928-03-31 0 1020 6 da… ## 10 MARYLAND 1928-04-01 1928-04-07 0 753 6 da… ## # … with 318 more rows 3.5.2 Grouping and Summarizing data Many data analysis tasks can be approached using the split-apply-combine paradigm: split the data into groups, apply some analysis to each group, and then combine the results. dplyr makes this very easy through the use of the group_by() function. group_by() is often used together with summarize(), which collapses each group into a single-row summary of that group. group_by() takes as arguments the column names that contain the categorical variables for which you want to calculate the summary statistics. Let’s return to our measles_us_mod data frame. To analyze this further, we need to separate out the rows that represent cumulative counts from the rows that have a fixed interval. So we use filter() as we did above, this time saving to a new object called non_cumulative_period. #filter out cumulative counts non_cumulative &lt;- measles_us_mod %&gt;% filter(PartOfCumulativeCountSeries == 0) How can we calculate the total number of measles cases in each state for each reported time period? First we need to group our data by state, and then group by period. Remember that in our original data set each state contained counts for multiple municipalities. That means in our current data frame there will be multiple rows for each period that needs to be condensed. #group - prepares for summary calculations count_by_period &lt;- non_cumulative %&gt;% group_by(State, PeriodStartDate) count_by_period ## # A tibble: 337,637 × 6 ## # Groups: State, PeriodStartDate [150,481] ## State PeriodStartDate PeriodEndDate PartOfCumulativeCou… CountValue Span ## &lt;chr&gt; &lt;date&gt; &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;drt&gt; ## 1 WISCONSIN 1927-11-20 1927-11-26 0 85 6 da… ## 2 WISCONSIN 1927-11-27 1927-12-03 0 120 6 da… ## 3 WISCONSIN 1927-12-04 1927-12-10 0 84 6 da… ## 4 WISCONSIN 1927-12-18 1927-12-24 0 106 6 da… ## 5 WISCONSIN 1927-12-25 1927-12-31 0 39 6 da… ## 6 WISCONSIN 1928-01-01 1928-01-07 0 45 6 da… ## 7 WISCONSIN 1928-01-08 1928-01-14 0 28 6 da… ## 8 WISCONSIN 1928-01-15 1928-01-21 0 140 6 da… ## 9 WISCONSIN 1928-01-22 1928-01-28 0 48 6 da… ## 10 WISCONSIN 1928-01-29 1928-02-04 0 85 6 da… ## # … with 337,627 more rows When you inspect your new data frame, everything should look the same. Grouping prepares your data for summarize, but it does not do anything visually to the data. Now let’s trying summarizing that data. summarize() takes the dataframe as it’s first argument, then you need to provide some calculation and the name for the new column where the results of that calculation will go. In this case, we will use the sum() function on the CountValue column and put this in a new column called TotalCount count_by_period &lt;- non_cumulative %&gt;% group_by(State, PeriodStartDate) %&gt;% summarize(TotalCount = sum(CountValue)) ## `summarise()` has grouped output by &#39;State&#39;. You can override using the ## `.groups` argument. Notice how the use of pipes really comes in handy here. It saved us from having to create and keep track of a number of intermediate objects. Now each row in our dataset represents a week of data. It might be better if we can look at yearly trends. So, let’s try separating out the year from PeriodStartDate into its own column. In addition to mutate(), we will also use the year() function from lubridate. Since lubridate is not loaded with the core tidyverse let’s go ahead and load that now. library(lubridate) ## ## Attaching package: &#39;lubridate&#39; ## The following objects are masked from &#39;package:base&#39;: ## ## date, intersect, setdiff, union Remember, you only need to install a package once, but you have to load it with each new session. #Get year in separate column from PeriodStartDate count_by_period &lt;- count_by_period %&gt;% mutate(Year = year(PeriodStartDate)) count_by_period ## # A tibble: 150,481 × 4 ## # Groups: State [56] ## State PeriodStartDate TotalCount Year ## &lt;chr&gt; &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 ALABAMA 1909-05-23 1 1909 ## 2 ALABAMA 1910-01-16 1 1910 ## 3 ALABAMA 1910-02-06 13 1910 ## 4 ALABAMA 1910-04-10 127 1910 ## 5 ALABAMA 1910-04-17 81 1910 ## 6 ALABAMA 1910-04-24 73 1910 ## 7 ALABAMA 1910-05-01 62 1910 ## 8 ALABAMA 1910-05-09 72 1910 ## 9 ALABAMA 1910-05-15 39 1910 ## 10 ALABAMA 1910-05-22 38 1910 ## # … with 150,471 more rows Now we can do our grouping and summarizing again as we did above. #Get totals for each state each year. yearly_count_state &lt;- count_by_period %&gt;% group_by(Year, State) %&gt;% summarise(TotalCount = sum(TotalCount)) ## `summarise()` has grouped output by &#39;Year&#39;. You can override using the ## `.groups` argument. yearly_count_state ## # A tibble: 4,210 × 3 ## # Groups: Year [96] ## Year State TotalCount ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 1906 CALIFORNIA 224 ## 2 1906 CONNECTICUT 23 ## 3 1906 FLORIDA 4 ## 4 1906 ILLINOIS 187 ## 5 1906 INDIANA 20 ## 6 1906 KENTUCKY 2 ## 7 1906 MAINE 26 ## 8 1906 MASSACHUSETTS 282 ## 9 1906 MICHIGAN 320 ## 10 1906 MISSOURI 274 ## # … with 4,200 more rows Alternatively, to see a national level summary, we could group just by Year #Get totals each year. yearly_count &lt;- count_by_period %&gt;% group_by(Year) %&gt;% summarise(TotalCount = sum(TotalCount)) yearly_count ## # A tibble: 96 × 2 ## Year TotalCount ## &lt;dbl&gt; &lt;dbl&gt; ## 1 1906 2345 ## 2 1907 40699 ## 3 1908 55632 ## 4 1909 56317 ## 5 1910 87191 ## 6 1911 62306 ## 7 1912 66388 ## 8 1913 117571 ## 9 1914 57363 ## 10 1915 95507 ## # … with 86 more rows 3.6 Joining Datasets Of course, looking at total counts in each state is not the most helpful metric without taking population into account. To rectify this, let’s try joining some historical population data with our measles data. First we need to import the population data. #load csv of populations by state over time, changing some of the datatypes from default hist_pop_by_state &lt;- read_csv( &quot;data/Historical_Population_by_State.csv&quot;, col_types = cols(ALASKA = col_double(), HAWAII = col_double()) ) View(hist_pop_by_state) As we saw in our measles data import, the presence of NAs makes it necessary to explicitly state that the Hawaii and Alaska columns contain numerical data. 3.6.1 Long vs Wide formats For data to be considered “tidy”, it should be in what is called “long” format. Each column is a variable, each row is an observation, and each cell is a value. Our state population data is in “wide” format, which is often preferable for human-readability, but is less ideal for machine-readability. We will use the package tidyr and the function pivot_longer to convert our population data to a long format, thus making it easier to join with our measles data. Each column in our population dataset represents a state. To make it tidy we are going to reduce those to one column called State with the state names as the values of the column. We will then need to create a new column for population containing the current cell values. To remember that the population data is provided in 1000s of persons, we will call this new column pop1000. pivot_longer() takes four principal arguments: the data cols are the names of the columns we use to fill the new values variable (or to drop). the names_to column variable we wish to create from the cols provided. the values_to column variable we wish to create and fill with values associated with the cols provided. library(tidyr) hist_pop_long &lt;- hist_pop_by_state %&gt;% pivot_longer(ALASKA:WYOMING, names_to = &quot;State&quot;, values_to = &quot;pop1000&quot;) View(hist_pop_long) Now our two datasets have similar structures, a column of state names, a column of years, and a column of values. Let’s join these two datasets by the state and year columns. Note that if both sets have the same column names, you do not need to specify anything in the by argument. We use a left join here which preserves all the rows in our measles dataset and adds the matching rows from the population dataset. joined_df &lt;- left_join(yearly_count_state, hist_pop_long, by=c(&quot;State&quot; = &quot;State&quot;, &quot;Year&quot; = &quot;DATE&quot; )) joined_df ## # A tibble: 4,210 × 4 ## # Groups: Year [96] ## Year State TotalCount pop1000 ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1906 CALIFORNIA 224 1976 ## 2 1906 CONNECTICUT 23 1033 ## 3 1906 FLORIDA 4 628 ## 4 1906 ILLINOIS 187 5309 ## 5 1906 INDIANA 20 2663 ## 6 1906 KENTUCKY 2 2234 ## 7 1906 MAINE 26 729 ## 8 1906 MASSACHUSETTS 282 3107 ## 9 1906 MICHIGAN 320 2626 ## 10 1906 MISSOURI 274 3223 ## # … with 4,200 more rows Now we can use our old friend mutate() to add a rate column calculated from the count and pop1000 columns. #Add column for rate (per 1000) of measles rate_by_year &lt;- mutate(joined_df, rate = TotalCount / pop1000) rate_by_year ## # A tibble: 4,210 × 5 ## # Groups: Year [96] ## Year State TotalCount pop1000 rate ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1906 CALIFORNIA 224 1976 0.113 ## 2 1906 CONNECTICUT 23 1033 0.0223 ## 3 1906 FLORIDA 4 628 0.00637 ## 4 1906 ILLINOIS 187 5309 0.0352 ## 5 1906 INDIANA 20 2663 0.00751 ## 6 1906 KENTUCKY 2 2234 0.000895 ## 7 1906 MAINE 26 729 0.0357 ## 8 1906 MASSACHUSETTS 282 3107 0.0908 ## 9 1906 MICHIGAN 320 2626 0.122 ## 10 1906 MISSOURI 274 3223 0.0850 ## # … with 4,200 more rows "],["plotting-with-ggplot2.html", "Chapter 4 Plotting with ggplot2 4.1 Barplots", " Chapter 4 Plotting with ggplot2 ggplot2 is a plotting package that makes it simple to create complex plots from data stored in a data frame. It provides a programmatic interface for specifying what variables to plot, how they are displayed, and general visual properties. Therefore, we only need minimal changes if the underlying data change or if we decide to change from a bar plot to a scatterplot. This helps in creating publication quality plots with minimal amounts of adjustments and tweaking. First, let’s load ggplot2. library(ggplot2) ggplot2 functions work best with data in the ‘long’ format, i.e., a column for every dimension, and a row for every observation. Well-structured data will save you lots of time when making figures with ggplot2 ggplot2 graphics are built step by step by adding new elements. Adding layers in this fashion allows for extensive flexibility and customization of plots. Each chart built with ggplot2 must include the following Data Aesthetic mapping (aes) Describes how variables are mapped onto graphical attributes Visual attribute of data including x-y axes, color, fill, shape, and alpha Geometric objects (geom) Determines how values are rendered graphically, as bars (geom_bar), scatterplot (geom_point), line (geom_line), etc. Thus, the template for graphic in ggplot2 is: &lt;DATA&gt; %&gt;% ggplot(aes(&lt;MAPPINGS&gt;)) + &lt;GEOM_FUNCTION&gt;() Remember from the last lesson that the pipe operator %&gt;% places the result of the previous line(s) into the first argument of the function. ggplot() is a function that expects a data frame to be the first argument. This allows for us to change from specifying the data = argument within the ggplot function and instead pipe the data into the function. use the ggplot() function and bind the plot to a specific data frame. yearly_count %&gt;% ggplot() Is the same as ggplot(data=yearly_count) define a mapping (using the aesthetic (aes) function), by selecting the variables to be plotted and specifying how to present them in the graph, e.g. as x/y positions or characteristics such as size, shape, color, etc. yearly_count %&gt;% ggplot(aes(x=Year, y=TotalCount)) This can also be written more concisely: yearly_count %&gt;% ggplot(aes(Year, TotalCount)) add ‘geoms’ – graphical representations of the data in the plot (points, lines, bars). ggplot2 offers many different geoms for common graph types. To add a geom to the plot use the + operator. Note to that you can save plots as objects. year_total_line &lt;- yearly_count %&gt;% ggplot(aes(x=Year, y=TotalCount)) + geom_line() year_total_line It might be nice to see where each data point falls on the line. To do this we can add another geometry layer. year_total_line &lt;- yearly_count %&gt;% ggplot(aes(x=Year, y=TotalCount)) + geom_line() + geom_point() year_total_line The + in the ggplot2 package is particularly useful because it allows you to modify existing ggplot objects. This means you can easily set up plot templates and conveniently explore different types of plots, so the above plot can also be generated with code like this: year_total_line &lt;- year_total_line + geom_point() year_total_line There are many ways to customize your plot, like changing the color or line type, adding labels and annotations. One thing that would make our graph easier to read is tick marks at each decade on the x-axis. year_total_line &lt;- yearly_count %&gt;% ggplot(aes(x=Year, y=TotalCount)) + geom_line() + geom_point() + scale_x_continuous(breaks = seq(1900, 2000, 10)) year_total_line Perhaps we would like to add some more information to our graph for context. Let’s drop a reference line at 1963 to clearly indicate on the graph when the vaccine was introduced. To do this we add a geom_vline() and the annotate() function. There are multiple ways of adding lines and text to a plot, but these will serve us well for this case. Note that you can change features of lines such as color, type, and size. year_total_line &lt;- yearly_count %&gt;% ggplot(aes(x=Year, y=TotalCount)) + geom_line() + geom_point() + scale_x_continuous(breaks = seq(1900, 2000, 10)) + geom_vline(xintercept = 1963, color = &quot;red&quot;, linetype= &quot;dashed&quot;) + annotate(geom = &quot;label&quot;, x=1963, y=80000, label=&quot;1963: vaccine introduced&quot;) year_total_line Finally, let’s add a title and axis labels to our plot with the labs() function. Note that axis labels will automatically be supplied from the column names, but you can use this function to override those defaults. year_total_line &lt;- yearly_count %&gt;% ggplot(aes(x=Year, y=TotalCount)) + geom_line() + geom_point() + scale_x_continuous(breaks = seq(1900, 2000, 10)) + geom_vline(xintercept = 1963, color = &quot;red&quot;, linetype= &quot;dashed&quot;) + annotate(geom = &quot;label&quot;, x=1963, y=800000, label=&quot;1963: vaccine introduced&quot;) + labs(title = &quot;Measles Cases Decrease After Vaccine Introduced&quot;, x = &quot;Year&quot;, y = &quot;Total Measles Case Count&quot;) year_total_line Finally, let’s save our plot to a png file, so we can share it or put it in reports. To do this we use the function called ggsave(). ggsave(&quot;images/yearly_measles_count.png&quot;, plot = year_total_line) 4.1 Barplots To emphasize that ggplot2 is part of the tidyverse along with dplyr, consider that you could clean some data and plot it in one step. Below we create a new plot that takes a closer look at measles cases in 1963. First we filter our dataset to look at rows for 1963, and then we use geom_bar to view each state. #Combine data cleaning and plotting in one step #plot the counts for each state in a bar graph in the year 1963, year vaccine was introduced. count_1963 &lt;- yearly_count_state %&gt;% filter(Year == 1963) %&gt;% ggplot(aes(x = State, y = TotalCount)) + geom_bar(stat = &quot;identity&quot;) + theme(axis.text.x = element_text(angle = 90)) count_1963 rate_1963 &lt;- rate_by_year %&gt;% filter(Year == 1963) %&gt;% ggplot(aes(x = State, y = rate)) + geom_bar(stat = &quot;identity&quot;) + theme(axis.text.x = element_text(angle = 90)) rate_1963 ## Warning: Removed 1 rows containing missing values (position_stack). It can be helpful to look at bar graphs sorted rate_1963 &lt;- rate_by_year %&gt;% filter(Year == 1963) %&gt;% ggplot(aes(x = reorder(State, -rate), y = rate)) + geom_bar(stat = &quot;identity&quot;) + theme(axis.text.x = element_text(angle = 90)) rate_1963 ## Warning: Removed 1 rows containing missing values (position_stack). "],["reproducible-project-management.html", "Chapter 5 Reproducible Project Management 5.1 RStudio Projects 5.2 Version Control and RStudio 5.3 Setting up a remote repository on Github 5.4 Connecting Rstudio to Github 5.5 Get a personal access token (PAT) 5.6 Checking out a project from a version control remote repository 5.7 Making some changes, save, commit. 5.8 Push your local changes online to GitHub 5.9 Confirm the local change propagated to the GitHub remote 5.10 Clean up", " Chapter 5 Reproducible Project Management Eventually you will be using R for various different analytic tasks not all corresponding to the same project. Knowing what really needs to be saved and establishing a procedure to keep all of the stuff together for any given project will help in preventing a data loss or information loss. To handle these real life situations, you need to determine: What about your analysis is “real”, i.e. what will you save as your lasting record of what happened? Where does your analysis “live”? 5.1 RStudio Projects Before tackling RStudio Projects lets orient ourselves a bit in RStudio and answer the questions from the beginning of the chapter as a segue to them. 5.1.1 What is Real? As a beginning R user, it’s OK to consider your environment (i.e. the objects listed in the environment pane) “real”. However, in the long run, you’ll be much better off if you consider your R scripts as “real”. With your R scripts (and your data files), you can recreate the environment. It’s much harder to recreate your R scripts from your environment! You’ll either have to retype a lot of code from memory (making mistakes all the way) or you’ll have to carefully mine your R history. To foster this behavior, its highly recommend that you instruct RStudio not to preserve your workspace between sessions: This will cause you some short-term pain, because now when you restart RStudio it will not remember the results of the code that you ran last time. But this short-term pain will save you long-term agony because it forces you to capture all important interactions in your code. There’s nothing worse than discovering three months after the fact that you’ve only stored the results of an important calculation in your workspace, not the calculation itself in your code. 5.1.2 Where does your analysis live? R has a powerful notion of the working directory. This is where R looks for files that you ask it to load, and where it will put any files that you ask it to save. RStudio shows your current working directory at the top of the console: And you can print this out in R code by running getwd(): getwd() ## [1] &quot;/Users/jpcourneya/Documents/CDABS/cdabs_r_series&quot; As a beginning R user, it’s OK to let your home directory, documents directory, or any other weird directory on your computer be R’s working directory. It is very important to evolve to organizing your analytic projects into directories and, when working on a project, setting R’s working directory to the associated directory. NOT RECOMMENDED, but you can also set the working directory from within R: setwd(&quot;/path/to/expert/coolProject&quot;) 5.1.3 Creating an RStudio project R experts keep all the files associated with a project together — input data, R scripts, analytical results, figures. This is such a wise and common practice that RStudio has built-in support for this via projects. Let’s practice creating a project. Click File &gt; New Project, then: Call your project T32-Session3 and think carefully about which subdirectory you put the project in. If you don’t store it somewhere sensible, it will be hard to find it in the future! Once this process is complete, you’ll get a new RStudio project just for this practice. Check that the “home” directory of your project is the current working directory: getwd() Whenever you refer to a file with a relative path it will look for it here. Now enter the following commands in the script editor, and save the file, calling it “diamonds.R”. Next, run the complete script which will save a PDF and CSV file into your project directory. library(tidyverse) ggplot(diamonds, aes(carat, price)) + geom_hex() ggsave(&quot;diamonds.pdf&quot;) write_csv(diamonds, &quot;diamonds.csv&quot;) Quit RStudio. Inspect the folder associated with your project — notice the .Rproj file. Double-click that file to re-open the project. Notice you get back to where you left off: it’s the same working directory and command history, and all the files you were working on are still open. Because you followed my instructions above, you will, however, have a completely fresh environment, guaranteeing that you’re starting with a clean slate. In your favorite OS-specific way, search your computer for diamonds.pdf and you will find the PDF (no surprise) but also the script that created it (diamonds.R). This is huge win! One day you will want to remake a figure or just understand where it came from. If you rigorously save figures to files with R code and never with the mouse or the clipboard, you will be able to reproduce old work with ease! 5.2 Version Control and RStudio 5.2.1 Why Git? Git is a version control system. Its original purpose was to help groups of developers work collaboratively on big software projects. Git manages the evolution of a set of files – called a repository – in a sane, highly structured way. If you have no idea what I’m talking about, think of it as the “Track Changes” features from Microsoft Word on steroids. Git has been re-purposed by the data science community. In addition to using it for source code, we use it to manage the motley collection of files that make up typical data analytical projects, which often consist of data, figures, reports, and, yes, source code. 5.2.2 What’s GitHub? GitHub, Bitbucket, and GitLab are online services that provide a home for your Git-based projects on the internet. If you have no idea what I’m talking about, think of them as DropBox but much, much better. The remote host acts as a distribution channel or clearinghouse for your Git-managed project. It allows other people to see your stuff, sync up with you, and perhaps even make changes. These hosting providers improve upon traditional Unix Git servers with well-designed web-based interfaces. Even for private solo projects, it’s a good idea to push your work to a remote location for peace of mind. Why? Because it’s fairly easy to screw up your local Git repository, especially when you’re new at this. The good news is that often only the Git infrastructure is borked up. Your files are just fine! Which makes your Git pickle all the more frustrating. There are official Git solutions to these problems, but they might require expertise and patience you can’t access at 3a.m. If you’ve recently pushed your work to GitHub, it’s easy to grab a fresh copy, patch things up with the changes that only exist locally, and get on with your life. Don’t get too caught up on public versus private at this point. There are many ways to get private repositories from the major providers for low or no cost. Just get started and figure out if and how Git/GitHub is going to work for you! We will not be covering all the in’s and outs of version control with Git, Github and all the resources to be found there since our time is limited. Instead you will learn how to: Set up a remote repository on Github Connecting RStudio to Github Set up a personal access token on Github Checking out a project from a version control remote repository Making some changes, using the Rstudio Git controls and pushing those changes to Github 5.3 Setting up a remote repository on Github First thing we do is navigate to Github and make sure youre logged in. Click green “New repository” button. Or, if you are on your own profile page, click on “Repositories”, then click the green “New” button. How to fill this in: Repository name: myrepo (or whatever you wish, we’ll delete this soon anyway). Description: “testing my setup” (or whatever, but some text is good for the README). Public. YES Initialize this repository with a README. For everything else, just accept the default. Click big green button “Create repository.” Copy the HTTPS clone URL to your clipboard via the green “Clone or Download” button. 5.4 Connecting Rstudio to Github Here we verify that RStudio can issue Git commands on your behalf. Assuming that you’ve gotten local Git to talk to GitHub, this means you’ll also be able to pull from and push to GitHub from RStudio. 5.4.1 Introduce yourself to Git The usethis package offers an approach to set your Git user name and email from within R as well as setting up a personal access token. To configure git: ## install if needed (do this exactly once): install.packages(&quot;usethis&quot;) library(usethis) use_git_config(user.name = &quot;Jane Doe&quot;, user.email = &quot;jane@example.org&quot;) Check what you just did usethis::git_sitrep()generates a git situation-report. It can help you confirm things will work as expected; it can also help you diagnose problems: library(usethis) git_sitrep() 5.4.1.1 Optional: configure Git’s editor Another Git option that many people eventually configure is the editor. This will come up if you use Git from a shell. At some point, you will fail to give Git what it wants in terms of a commit message and it will kick you into an editor. This can be distressing, if it’s not your editor of choice and you don’t even know how to save and quit. You can enforce your will by executing this in R: library(usethis) use_git_config(core.editor = &quot;nano&quot;) 5.5 Get a personal access token (PAT) 5.5.1 Create the PAT In this step you will be creating a PAT. Since GitHub is moving away from username + password to push to their server it will be inevitable that you must set this up to work with GitHub from your local computer and RStudio. To create the token using usethis run: usethis::create_github_token() You will see running this command takes you to a pre-filled form to create a new PAT. You can get to the same page in the browser by clicking on “Generate new token” from (https://github.com/settings/tokens). The advantage of create_github_token() is that the usethis maintainers have pre-selected some recommended scopes, which you can look over and adjust before clicking “Generate token”. It is a very good idea to give the token a descriptive name, because one day you might have multiple PATs, e.g., one that’s configured on your main work computer and another that you use from a secondary computer or VM. Eventually, you’ll need to “spring clean” your PATs and this is much less nerve-wracking if you know which PAT is being used where and for what. You must store this token somewhere, because you’ll never be able to see it again, once you leave this browser window. If you somehow goof this up, just generate a new PAT and, so you don’t confuse yourself, delete the lost token. In the moment, we usually copy the PAT to the clipboard, anticipating what we’ll do next: trigger a prompt that lets us store the PAT in the Git credential store. 5.5.2 Put your PAT into the Git credential store Next you need to run: gitcreds::gitcreds_set() You will have the gitcreds package installed, as of usethis v2.0.0, because usethis uses gh, and gh uses gitcreds. If you don’t have a PAT stored already, it will prompt you to enter your PAT. Paste! If you do already have a stored credential, gitcreds::gitcreds_set() reveals this and will even let you inspect it. This helps you decide whether to keep the existing credential or replace it. When in doubt, embrace a new, known-to-be-good credential over an old one, of uncertain origins. Here are two great ways to check that all is well: gh::gh_whoami() usethis::git_sitrep() Both of these functions reveal whether a GitHub PAT is discovered and provide information about the associated user, the PAT’s scopes, etc. This step is something you do once. Or, rather, once per machine, per PAT. From this point on, usethis and its dependencies should be able to automatically retrieve and use this PAT. 5.6 Checking out a project from a version control remote repository Hopefully it has been a joy configuring your Git setup on your computer. Now we will put all of that machinery to work and test it out. Picking up were we left off when Setting up a remote repository copy the HTTPS clone URL to your clipboard via the green “Clone or Download” button. 5.6.1 Clone the new GitHub repository to your computer via RStudio In RStudio, start a new Project review here: File &gt; New Project &gt; Version Control &gt; Git. In “Repository URL”, paste the URL of your new GitHub repository. It will be something like this https://github.com/j-p-courneya/T32_Session3_Practice.git. Do you NOT see an option to get the Project from Version Control? Restart RStudio and try again. Still no luck? Go to gitwithr chapter 13 for tips on how to help RStudio find Git. Accept the default project directory name, e.g. T32_Session3_Practice, which coincides with the GitHub repo name. Take charge of – or at least notice! – where the Project will be saved locally. A common rookie mistake is to have no idea where you are saving files or what your working directory is. Pay attention. Be intentional. Personally, I would do this in ~/Documents. I suggest you check “Open in new session”, as that’s what you’ll usually do in real life. Click “Create Project”. You should find yourself in a new local RStudio Project that represents the new test repo we just created on GitHub. This should download the README.md file from GitHub. Look in RStudio’s file browser pane for the README.md file. 5.7 Making some changes, save, commit. From RStudio, modify the README.md file, e.g., by adding the line “This is a line from RStudio”. Save your changes. Commit these changes to your local repo. How? From RStudio: Click the “Git” tab in upper right pane. Check “Staged” box for README.md. If you’re not already in the Git pop-up, click “Commit”. Type a message in “Commit message”, such as “Commit from * RStudio”. Click “Commit”. 5.8 Push your local changes online to GitHub Click the green “Push” button to send your local changes to GitHub. You should see some message along these lines. [master dc671f0] blah 3 files changed, 22 insertions(+) create mode 100644 .gitignore create mode 100644 myrepo.Rproj 5.9 Confirm the local change propagated to the GitHub remote Go back to the browser. I assume we’re still viewing your new GitHub repo. Refresh. You should see the new “This is a line from RStudio” in the README. If you click on “commits”, you should see one with the message “Commit from RStudio”. If you have made it this far, you are DONE with set up. 5.10 Clean up Local When you’re ready to clean up, you can delete the local repo any way you like. It’s just a regular directory on your computer. GitHub In the browser, go to your repo’s landing page on GitHub. Click on “Settings”. Scroll down, click on “delete repository,” and do as it asks. "],["reproducible-reports-with-r-markdown.html", "Chapter 6 Reproducible Reports with R Markdown 6.1 What is R Markdown 6.2 R Markdown Related Packages 6.3 How does R Markdown work 6.4 Resources for R Markdown", " Chapter 6 Reproducible Reports with R Markdown So far, you’ve learned the tools to get your data into R, tidy it into a form convenient for analysis, and then understand your data through transformation and visualization. We have not covered modeling (The goal of a model is to provide a simple low-dimensional summary of a dataset.) It doesn’t matter how great your analysis is unless you can explain it to others and provide your analysis in a way that is reproducibly by others: you need to communicate your results. Many new users begin by first writing a single R script containing all of their work, and then share the analysis by emailing the script and various graphs as attachments. But this can be cumbersome, requiring a lengthy discussion to explain which attachment was which result. Writing formal reports with Word can simplify this process by incorporating both the analysis report and output graphs into a single document. But tweaking formatting to make figures look correct and fixing obnoxious page breaks can be tedious and lead to a lengthy “whack-a-mole” game of fixing new mistakes resulting from a single formatting change. 6.1 What is R Markdown R Markdown provides an authoring framework for data science. You can use a single R Markdown file to both save and execute code, and generate high quality reports that can be shared with an audience. R Markdown was designed for easier reproducibility, since both the computing code and narratives are in the same document, and results are automatically generated from the source code. R Markdown supports dozens of static and dynamic/interactive output formats like word, pdf, powerpoint and more! To use Rmarkdown you need the rmarkdown package, but you don’t need to explicitly install it or load it, as RStudio automatically does both when needed. 6.2 R Markdown Related Packages In addition to the amazing reports and even slide decks that you can produce with Rmarkdown one of the other amazing features is that it can also be used to create your own website using the package blogdown and author books using the bookdown package. These two abilities truly extend the reach of your work essentially making it available to anyone with a web browser and internet connection. bookdown is an R package that allows you to write books and long-form reports with multiple Rmd files. After this package was published, a large number of books have emerged. You can find a subset of them at (https://bookdown.org). Some of these books have been printed, and some only have free online versions. There have also been students who wrote their dissertations/theses with bookdown, such as Ed Berry: (https://eddjberry.netlify.com/post/writing-your-thesis-with-bookdown/). Chester Ismay has even provided an R package thesisdown (https://github.com/ismayc/thesisdown) that can render a thesis in various formats. The blogdown package can be used to build general-purpose websites (including blogs and personal websites) based on R Markdown. You may find tons of examples at (https://github.com/rbind) or by searching on Twitter: (https://twitter.com/search?q=blogdown). 6.3 How does R Markdown work Lets take a look under the hood at R Markdown. The best way to get a sense of whats going on is to create a R Markdown file using RStudio. 6.3.1 Creating an R Markdown file Within RStudio, click File → New File → R Markdown and you’ll get a dialog box like this: You can stick with the default (HTML output), but give it a title. As a result RStudio generates this: 6.3.2 R Markdown Basic Components What we see is an R Markdown file, a plain text file that has the extension .Rmd: It contains three important types of content: An (optional) YAML header surrounded by ---s. Chunks of R code surrounded by ```. Text mixed with simple text formatting like # heading and _italics_. 6.3.2.1 YAML Header The initial chunk of text (header) contains instructions for R to specify what kind of document will be created, and the options chosen. You can use the header to give your document a title, author, date, and tell it what type of output you want to produce. In this case, we’re creating an html document. The syntax for the metadata is YAML (YAML Ain’t Markup Language, (https://en.wikipedia.org/wiki/YAML)), so sometimes it is also called the YAML metadata or the YAML frontmatter. Before it bites you hard, we want to warn you in advance that indentation matters in YAML, so do not forget to indent the sub-fields of a top field properly. --- title: &quot;T32-Rmd-Practice&quot; author: &quot;JP Courneya&quot; date: &quot;7/21/2021&quot; output: html_document --- 6.3.2.2 Body of the document The body of the document follows the metadata. The syntax for text (also known as prose or narratives) is Markdown, a lightweight set of conventions for formatting plain text files. Markdown is designed to be easy to read and easy to write. There are also two types of computer code, code chunks and inline R code. We will look at each of these in more detail in subsequent sections. You will notice in the .Rmd interface the code and output are interleaved. You can run each code chunk by clicking the Run icon (it looks like a play button at the top of the chunk), or by pressing Cmd/Ctrl + Shift + Enter. RStudio executes the code and displays the results inline with the code: To generate a report from the file, run the render command: library(rmarkdown) render(&quot;T32-rmd-practice.Rmd&quot;) Better still, use the button in the RStudio IDE to render the file and preview the output with a single click or keyboard shortcut (⇧⌘K). You will notice your first time “knitting” the document you are prompted to save the file, save it with a meaningful name. R Markdown generates a new file that contains selected text, code, and results from the .Rmd file. 6.3.2.3 How things get compiled When you run render, or press the button, R Markdown feeds the .Rmd file to knitr, which executes all of the code chunks and creates a new markdown (.md) document which includes the code and its output. The markdown file generated by knitr is then processed by pandoc which is responsible for creating the finished format. This may sound complicated, but R Markdown makes it extremely simple by encapsulating all of the above processing into a single render function or button. 6.3.3 Markdown Markdown is a system for writing web pages by marking up the text much as you would in an email rather than writing html code. The marked-up text gets converted to html, replacing the marks with the proper html code. For now, let’s delete all of the stuff that’s in the .Rmd file and write a bit of markdown. You make things bold using two asterisks, like this: **bold**, and you make things italics by using underscores, like this: _italics_. You can make a bulleted list by writing a list with hyphens or asterisks, like this: * one item * one item * one item * one more item * one more item * one more item - bold with double-asterisks - italics with underscores - code-type font with backticks The output is: one item one item one item one more item one more item one more item bold with double-asterisks italics with underscores code-type font with backticks You can use whatever method you prefer, but be consistent. This maintains the readability of your code. You can make a numbered list by just using numbers. You can even use the same number over and over if you want: 1. bold with double-asterisks 1. italics with underscores 1. code-type font with backticks This will appear as: bold with double-asterisks italics with underscores code-type font with backticks You can make section headers of different sizes by initiating a line with some number of # symbols: # Title ## Main section ### Sub-section #### Sub-sub section They will appear like this: 6.3.3.1 A bit more Markdown You can make a hyperlink like this: [text to show](http://the-web-page.com). You can include an image file like this: ![caption](http://url/for/file) You can do subscripts (e.g., F2) with F~2~ and superscripts (e.g., F2) with F^2^. If you know how to write equations in LaTeX, you can use $ $ and $$ $$ to insert math equations, like $E = mc^2$ and $$y = \\mu + \\sum_{i=1}^p \\beta_i x_i + \\epsilon$$ 6.3.4 R code chunks The real power of Markdown comes from mixing markdown with chunks of code. This is R Markdown. When processed, the R code will be executed; if they produce figures, the figures will be inserted in the final document. To run code inside an R Markdown document, you need to insert a chunk. There are three ways to do so: The keyboard shortcut Cmd/Ctrl + Alt + I The “Insert” button icon in the editor toolbar. By manually typing the chunk delimiters ```{r} and ```. I’d recommend you learn the keyboard shortcut. It will save you a lot of time in the long run! The main code chunks look like this: ```{r} summary(cars) ``` You should give each chunk a unique name, as they will help you to fix errors and, if any graphs are produced, the file names are based on the name of the code chunk that produced them. As an exercise add code chunks to: download gapminder data to /data Load the ggplot2 package Read the gapminder data Create a plot ```{r download-gapminder-data, eval=TRUE} download.file(&quot;https://raw.githubusercontent.com/swcarpentry/r-novice-gapminder/gh-pages/_episodes_rmd/data/gapminder_data.csv&quot;, destfile = &quot;data/gapminder_data.csv&quot;) ``` ```{r load-ggplot2, eval=TRUE} library(&quot;ggplot2&quot;) ``` ```{r read-gapminder-data, eval=TRUE} gapminder &lt;- read.csv(file = &quot;data/gapminder_data.csv&quot;, stringsAsFactors = TRUE) ``` ```{r make-plot, eval=TRUE} plot(lifeExp ~ year, data = gapminder) ``` As a courtesy the code to copy and place in chunks: download.file(&quot;https://raw.githubusercontent.com/swcarpentry/r-novice-gapminder/gh-pages/_episodes_rmd/data/gapminder_data.csv&quot;, destfile = &quot;data/gapminder_data.csv&quot;) library(ggplot2) gapminder &lt;- read.csv(file = &quot;data/gapminder_data.csv&quot;, stringsAsFactors = TRUE) plot(lifeExp ~ year, data = gapminder) 6.3.4.1 Chunk Options There are a variety of options to affect how the code chunks are treated. Here are some examples: Use echo=FALSE to avoid having the code itself shown. Use results=\"hide\" to avoid having any results printed. Use eval=FALSE to have the code shown but not evaluated. Use warning=FALSE and message=FALSE to hide any warnings or messages produced. Use fig.height and fig.width to control the size of the figures produced (in inches). So you might write: ```{r load_libraries, echo=FALSE, message=FALSE} library(&quot;dplyr&quot;) library(&quot;ggplot2&quot;) ``` Often there will be particular options that you’ll want to use repeatedly; for this, you can set global chunk options, like so: ```{r global_options, echo=FALSE} knitr::opts_chunk$set(fig.path=&quot;Figs/&quot;, message=FALSE, warning=FALSE, echo=FALSE, results=&quot;hide&quot;, fig.width=11) ``` The fig.path option defines where the figures will be saved. The / here is really important; without it, the figures would be saved in the standard place but just with names that begin with Figs. If you have multiple R Markdown files in a common directory, you might want to use fig.path to define separate prefixes for the figure file names, like fig.path=\"Figs/cleaning-\" and fig.path=\"Figs/analysis-\". You can review all of the R chunk options by navigating to the “R Markdown Cheat Sheet” under the “Cheatsheets” section of the “Help” field in the toolbar at the top of RStudio. 6.3.4.2 Inline code There is one other way to embed R code into an R Markdown document: directly into the text, with: r. This can be very useful if you mention properties of your data in the text. For example, using the diamonds dataset we could report: We have data about r nrow(ggplot2::diamonds diamonds. The output would be: We have data about 53940 diamonds. When inserting numbers into text, format() is your friend. It allows you to set the number of digits so you don’t print to a ridiculous degree of accuracy, and a big.mark to make numbers easier to read. The expression: We have data about `r format(nrow(ggplot2::diamonds), digits = 2, big.mark = \",\")` diamonds. Would look like this: We have data about 53,940 diamonds. You can combine these into a helper function: comma &lt;- function(x) format(x, digits = 2, big.mark = &quot;,&quot;) comma(3452345) ## [1] &quot;3,452,345&quot; comma(.12358124331) ## [1] &quot;0.12&quot; Using our nifty helper function, The expression will now look different `r comma(nrow(ggplot2::diamonds))` But give us the same amazing results as `r format(nrow(ggplot2::diamonds), digits = 2, big.mark = \",\")` ! We have data about 53,940 diamonds. 6.4 Resources for R Markdown Knitr in a knutshell tutorial Dynamic Documents with R and knitr (book) R Markdown documentation R Markdown cheat sheet Getting started with R Markdown R Markdown: The Definitive Guide (book by Rstudio team) Reproducible Reporting The Ecosystem of R Markdown Introducing Bookdown "],["shiny-apps.html", "Chapter 7 Shiny Apps 7.1 Shiny app basics 7.2 Create an empty Shiny app 7.3 An example Shiny App 7.4 Host your Shiny App 7.5 Resources", " Chapter 7 Shiny Apps Shiny is a package from RStudio that can be used to build interactive web pages with R. While that may sound scary because of the words “web pages”, Shiny is geared to R users who have zero experience with web development, and you do not need to know any HTML/CSS/JavaScript. You can do quite a lot with Shiny: think of it as an easy way to make an interactive web page, and that web page can seamlessly interact with R and display R objects (plots, tables, of anything else you do in R). To get a sense of the wide range of things you can do with Shiny, you can visit Dean Attali’s Shiny server (https://attalitech.com/#portfolio), which hosts a variety of Shiny apps. 7.1 Shiny app basics Every Shiny app is composed of two parts: a web page that shows the app to the user called the UI (user interface), and a computer that powers the app known as the server. The computer that runs the app can either be your own laptop (such as when you’re running an app from RStudio) or a server somewhere else. You, as the Shiny app developer, need to write these two parts. If you look at the app that can be built following the instructions here: tutorial , the page that you see is built with the UI code. UI is just a web document that the user gets to see, it’s HTML that you write using Shiny’s functions. The UI is responsible for creating the layout of the app and telling Shiny exactly where things go like controls to adjust the price or choose a country or where the plot and table appear on the page. The server is responsible for the logic of the app; it’s the set of instructions that tell the web page what to show, like the data for the table and the plot seen, when the user interacts with the page. 7.2 Create an empty Shiny app All Shiny apps follow the same template: library(shiny) ui &lt;- fluidPage( &quot;Hello, world!&quot; ) server &lt;- function(input, output, session) { } shinyApp(ui, server) This template is by itself a working minimal Shiny app that doesn’t do much. It calls library(shiny) to load the shiny package, initializes a UI containing the words “Hello, world!” and then specifies the behavior of our app by defining a server function, this server is empty so it doesnt do anything, and runs an app using shinyApp(ui, server) using the parts from UI and server. Copy the above template into a new file named app.R in a new folder. It is very important that the name of the file is app.R, otherwise it would not be recognized as a Shiny app. It is also very important that you place this app in its own folder, and not in a folder that already has other R scripts or files, unless those other files are used by your app. After saving the file, RStudio should recognize that this is a Shiny app, and you should see the usual Run button at the top change to Run App. If you don’t see the Run App button, it means you either have a very old version of RStudio, don’t have Shiny installed, or didn’t follow the file naming conventions. Click the Run App button, and now your app should run. You will have an amazing message in your Shiny App that looks like this: Take a moment and see that the R Console has some text printed in the form of Listening on http://127.0.0.1:5274 and that a little stop sign appeared at the top of the R Console. You’ll also notice that you can’t run any commands in the R Console. This is because R is busy - your R session is currently powering a Shiny app and listening for user interaction (which won’t happen because the app has no inputs in it yet). Click the stop button to stop the app, or press the Escape key. You may have noticed that when you click the Run App button, all it’s doing is just running the function shiny::runApp() in the R Console You can run that command instead of clicking the button if you prefer. Exercise: Try running the empty app using the runApp() function instead of using the Run App button. 7.2.1 Alternate way to create a Shiny app: separate UI and server files Another way to define a Shiny app is by separating the UI and server code into two files: ui.R and server.R. This is the preferable way to write Shiny apps when the app is complex and involves more code. If you want to break up your app into these two files, you simply put all code that is assigned to the ui variable in ui.R and all the code assigned to the server function in server.R. When RStudio sees these two files in the same folder, it will know you’re writing a Shiny app. 7.2.2 Let RStudio fill out a Shiny app template for you You can also create a new Shiny app using RStudio’s menu by selecting File &gt; New File &gt; Shiny Web App…. If you do this, RStudio will let you choose if you want a single-file app (app.R) or a two-file app (ui.R+server.R). RStudio will initialize a simple functional Shiny app with some code in it. 7.3 An example Shiny App Now that you have the basics, add the following code, run the app and check out the results: Replace your UI code with this: ui &lt;- fluidPage( selectInput(&quot;dataset&quot;, label = &quot;Dataset&quot;, choices = ls(&quot;package:datasets&quot;)), verbatimTextOutput(&quot;summary&quot;), tableOutput(&quot;table&quot;) ) Here youre providing a layout function with fluidPage() to set up the visual structure of the page, an input control for user interaction with selectInput(), verbatimTextOutput() and tableOutput() are output controls that tell Shiny where to put rendered output. Spend some time poking around to see how each of these functions operate under the hood. Replace your server code with this: server &lt;- function(input, output, session) { output$summary &lt;- renderPrint({ dataset &lt;- get(input$dataset, &quot;package:datasets&quot;) summary(dataset) }) output$table &lt;- renderTable({ dataset &lt;- get(input$dataset, &quot;package:datasets&quot;) dataset }) } Defining the server function is like putting a brain in the app. Now it can receive signals and tell the app what to do. The left-hand side of the assignment operator (&lt;-), output$ID, indicates that you’re providing the recipe for the Shiny output with that ID. The right-hand side of the assignment uses a specific render function to wrap some code that you provide. Each render{Type} function is designed to produce a particular type of output (e.g. text, tables, and plots), and is often paired with a {type}Output function. For example, in this app, renderPrint() is paired with verbatimTextOutput() to display a statistical summary with fixed-width (verbatim) text, and renderTable() is paired with tableOutput() to show the input data in a table. Run the app now and see what happens when you change the input! You will joyfully notice that the summary and table update whenever you change the input data from the dropdown menu. This dependency is created implicitly because we’ve referred to input$dataset within the output functions. input$dataset is populated with the current value of the UI component with id dataset, and will cause the outputs to automatically update whenever that value changes. This is a fundamental concept in Shiny known as reactivity, outputs automatically react when their inputs change. There is much to learn about this! 7.4 Host your Shiny App Once you have built a killer Shiny App you will want to show all of your friends and colleagues. Fortunately when youre starting out this can be done at no cost using the power of shinyapps.io! Deployment to the web is done using integrated Rstudio resources . When youre ready to step up your hosting game you can evolve to a paid tier within shinyapps.io, or host on your own server or a number of other places. Have fun with it! 7.5 Resources Shiny is a very popular package and has lots of resources on the web. Here’s a compiled list of a few recommended resources which are all fairly easy to read and understand. Shiny official website Shiny official tutorial Shiny cheatsheet Lots of short useful articles about different topics in Shiny - highly recommended Shiny in R Markdown Get help from the Shiny Google group or StackOverflow Publish your apps for free with shinyapps.io Host your app on your own Shiny server Learn about how reactivity works Learn about useful debugging techniques "],["further-resources.html", "A Further Resources A.1 Installing R and RStudio A.2 The Tidyverse A.3 Graphing in R A.4 R Based Technologies", " A Further Resources A.1 Installing R and RStudio Comprehensive R Archive Network (CRAN): https://cran.r-project.org/ RStudio: https://www.rstudio.com/products/rstudio/download/ A.2 The Tidyverse Tidyverse homepage: https://www.tidyverse.org/ R for Data Science: https://r4ds.had.co.nz/ A.3 Graphing in R R Graph Gallery: https://www.r-graph-gallery.com/ STHDA R DataViz QuickStart Guides: http://www.sthda.com/english/wiki/data-visualization R Graphics Cookbook: https://r-graphics.org/ A.4 R Based Technologies R Markdown: https://rmarkdown.rstudio.com/ R Markdown Cookbook: https://bookdown.org/yihui/rmarkdown-cookbook/ Bookdown: https://bookdown.org/ Authoring Books and Technical Documents with R Markdown: https://bookdown.org/yihui/bookdown/ Shiny: https://shiny.rstudio.com/ "],["selected-glossary-of-r-terminology.html", "B Selected Glossary of R Terminology", " B Selected Glossary of R Terminology Definitions from Glosario argument: one of possibly several expressions that are passed to a function. assignment operator: Symbol that assigns values on the right to an object on the left. Looks like &lt;-. Keyboard shortcut is Alt + - comment: Text written in a script that is not treated as code to be run, but rather as text that describes what the code is doing. These are usually short notes, beginning with a # Comprehensive R Archive Network (CRAN): A public repository of R packages. data frame: A two-dimensional data structure for storing tabular data in memory. Rows represent records and columns represent variables. function: A code block which gathers a sequence of operations into a whole, preserving it for ongoing use by defining a set of tasks that takes zero or more required and optional arguments as inputs and returns expected outputs (return values), if any. Functions enable repeating these defined tasks with one command, known as a function call. object: A data set, a variable, plot, or more formally, almost everything in R. If it has a mode, it is an object. Includes data frames, vectors, matrices, arrays, lists and functions. pipe operator: The %&gt;% used to make the output of one function the input of the next. package: A collection of code, data, and documentation that can be distributed and re-used. Also referred to in some languages as a library or module. reproducible research: The practice of describing and documenting research results in such a way that another researcher or person can re-run the analysis code on the same data to obtain the same result. tibble: A modern replacement for R’s data frame, which stores tabular data in columns and rows, defined and used in the tidyverse. tidy data: Tabular data that satisfies three conditions that facilitate initial cleaning, and later exploration and analysis—(1) each variable forms a column, (2) each observation forms a row, and (3) each type of observation unit forms a table. Tidyverse: A collection of R packages for operating on tabular data in consistent ways. "],["packages-and-functions-used.html", "C Packages and Functions Used", " C Packages and Functions Used readr read_csv(): import data from csv files dplyr glimpse(): look at list of columns in data frame select(): picks variables (columns) based on their names mutate(): create new variables (columns) based on existing variables (columns) count(): count unique values of one or more values filter(): Subset rows using column values group_by(): group data by one or more variables summarize() or summarise(): summarize each group to fewer rows. Creates new data frame. ggplot2 ggplot(): initializes a ggplot object geom_line(): connects variables in order of variable on x axis. Used to create a line graph geom_point(): used to create scatterplot, or add points to data on graph scale_x_continous(): adjusts scale of continous variables on x axis. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
